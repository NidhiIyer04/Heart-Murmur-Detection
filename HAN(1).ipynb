{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9b07762-a3dd-4011-aa7b-eaefe225d0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\nidhi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\nidhi\\anaconda3\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\nidhi\\anaconda3\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\nidhi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\nidhi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\nidhi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\nidhi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\nidhi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\nidhi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\nidhi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\nidhi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\nidhi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\nidhi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\nidhi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\nidhi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\nidhi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\nidhi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\nidhi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\nidhi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.68.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\nidhi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\nidhi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\nidhi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\nidhi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\nidhi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\nidhi\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\nidhi\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\users\\nidhi\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\nidhi\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nidhi\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nidhi\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nidhi\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nidhi\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.7.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\nidhi\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\nidhi\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\nidhi\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\nidhi\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\nidhi\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\nidhi\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\nidhi\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk \n",
    "nltk.download('punkt')\n",
    "!pip install tensorflow\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "defce3d7-b27b-4576-9b30-7563c7dd094a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Murmur': 'Murmur: Present', 'Murmur Location': 'Murmur Locations: TV', 'Most Audible Location': 'Most Audible Location: TV', 'Outcome': 'Outcome: Abnormal', 'Campaign': 'Campaign: CC2015'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"output_file.csv\")\n",
    "\n",
    "# Example row processing function\n",
    "def process_row(row):\n",
    "    patient_data = {}\n",
    "\n",
    "    # Define features as sentences (you can add more columns based on your need)\n",
    "    patient_data['Murmur'] = f\"Murmur: {row['Murmur']}\"\n",
    "    patient_data['Murmur Location'] = f\"Murmur Locations: {row['Murmur locations']}\"\n",
    "    patient_data['Most Audible Location'] = f\"Most Audible Location: {row['Most audible location']}\"\n",
    "    patient_data['Outcome'] = f\"Outcome: {row['Outcome']}\"\n",
    "    patient_data['Campaign'] = f\"Campaign: {row['Campaign']}\"\n",
    "\n",
    "    return patient_data\n",
    "\n",
    "# Apply to each row\n",
    "processed_data = df.apply(process_row, axis=1)\n",
    "\n",
    "# Example output for the first patient\n",
    "print(processed_data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cabd2dc-b635-44a8-8346-c93a0f1446b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.125 0.175 0.225]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Example GloVe embedding dictionary (you'll want to load the actual embeddings)\n",
    "glove_embeddings = {'Murmur': np.array([0.1, 0.2, 0.3]), 'Present': np.array([0.4, 0.5, 0.6])}  # Just an example\n",
    "\n",
    "# Ensure the word embeddings have a consistent shape (e.g., 3-dimensional vectors)\n",
    "embedding_dim = 3  # For demonstration; use 50, 100, 300 for GloVe embeddings.\n",
    "\n",
    "# Tokenize and embed a sentence\n",
    "def get_sentence_embedding(sentence):\n",
    "    words = word_tokenize(sentence)\n",
    "    \n",
    "    # Ensure each word is converted to a consistent-sized embedding\n",
    "    word_embeddings = []\n",
    "    for word in words:\n",
    "        embedding = glove_embeddings.get(word, np.zeros(embedding_dim))  # Default to zeros if word not found\n",
    "        word_embeddings.append(embedding)\n",
    "    \n",
    "    # If there are no word embeddings (e.g., the sentence was empty), return a zero vector\n",
    "    if not word_embeddings:\n",
    "        return np.zeros(embedding_dim)\n",
    "    \n",
    "    # Compute the average of the word embeddings in the sentence\n",
    "    sentence_embedding = np.mean(word_embeddings, axis=0)  # Average embedding\n",
    "    return sentence_embedding\n",
    "\n",
    "# Example processed sentence (e.g., \"Murmur: Present.\")\n",
    "sentence = \"Murmur: Present.\"\n",
    "\n",
    "# Get the embedding for the sentence\n",
    "sentence_embedding = get_sentence_embedding(sentence)\n",
    "print(sentence_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc3047eb-74c4-4baa-82a6-2514b21cc7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.125 0.175 0.225]\n"
     ]
    }
   ],
   "source": [
    "# Example sentence embedding\n",
    "print(sentence_embedding)  # Output: array([0.25, 0.35, 0.45])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85bf8f19-81fc-4ff0-a98b-81c47df9f5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Patient ID', 'Age', 'Sex', 'Height', 'Weight', 'Pregnancy status',\n",
      "       'Murmur', 'Murmur locations', 'Most audible location',\n",
      "       'Systolic murmur timing', 'Systolic murmur shape',\n",
      "       'Systolic murmur grading', 'Systolic murmur pitch',\n",
      "       'Systolic murmur quality', 'Diastolic murmur timing',\n",
      "       'Diastolic murmur shape', 'Diastolic murmur grading',\n",
      "       'Diastolic murmur pitch', 'Diastolic murmur quality', 'Outcome',\n",
      "       'Campaign', 'Additional ID', 'AV Sound Type', 'AV Murmur Timings',\n",
      "       'PV Sound Type', 'PV Murmur Timings', 'TV Sound Type',\n",
      "       'TV Murmur Timings', 'MV Sound Type', 'MV Murmur Timings'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f8b28fc-ea84-4c1d-ad14-3adb0ba3bfdd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First patient sentence embeddings: [array([0.025, 0.05 , 0.075]), array([0., 0., 0.]), array([0.16666667, 0.23333333, 0.3       ]), array([0.025, 0.05 , 0.075]), array([0.025, 0.05 , 0.075])]\n",
      "First patient target labels: {'Murmur Present': True, 'Severity': 'I/VI', 'Type': 'Unknown', 'Most Audible Location': 'TV'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Step 1: Load the CSV file\n",
    "df = pd.read_csv(\"output_file.csv\")  # Adjust the path to your actual CSV file\n",
    "\n",
    "# Example GloVe embedding dictionary (you'll want to load the actual embeddings)\n",
    "glove_embeddings = {'Murmur': np.array([0.1, 0.2, 0.3]), 'Present': np.array([0.4, 0.5, 0.6])}  # Just an example\n",
    "\n",
    "# Set the embedding dimensions\n",
    "embedding_dim = 3  # For demonstration, use the actual GloVe embedding size in practice (e.g., 50, 100, 300)\n",
    "\n",
    "# Step 2: Process each row (each patient)\n",
    "def process_row(row):\n",
    "    patient_data = []\n",
    "    patient_data.append(f\"Murmur Location: {row['Murmur locations']}\")\n",
    "    patient_data.append(f\"Most Audible Location: {row['Most audible location']}\")\n",
    "\n",
    "    # Create sentences for each patient from relevant columns\n",
    "    patient_data.append(f\"Murmur: {row['Murmur']}\")\n",
    "    patient_data.append(f\"Systolic Murmur: {row['Systolic murmur grading']}\")\n",
    "    patient_data.append(f\"Murmur Location: {row['Murmur locations']}\")\n",
    "\n",
    "\n",
    "    return patient_data\n",
    "\n",
    "# Process all rows\n",
    "patients_data = df.apply(process_row, axis=1)\n",
    "\n",
    "# Step 3: Tokenize and embed each sentence\n",
    "def get_sentence_embedding(sentence):\n",
    "    words = word_tokenize(sentence)\n",
    "    word_embeddings = [glove_embeddings.get(word, np.zeros(embedding_dim)) for word in words]\n",
    "    \n",
    "    if not word_embeddings:\n",
    "        return np.zeros(embedding_dim)\n",
    "    \n",
    "    # Compute the average embedding for the sentence\n",
    "    return np.mean(word_embeddings, axis=0)\n",
    "\n",
    "# Generate sentence embeddings for each patient\n",
    "patient_embeddings = {index: [get_sentence_embedding(sentence) for sentence in sentences]\n",
    "                      for index, sentences in enumerate(patients_data)}\n",
    "\n",
    "# Step 4: Define target labels (for example, you can extract labels from specific columns)\n",
    "def get_murmur_type(row):\n",
    "    systolic_value = str(row['Systolic murmur timing']) if pd.notna(row['Systolic murmur timing']) else \"\"\n",
    "    diastolic_value = str(row['Diastolic murmur timing']) if pd.notna(row['Diastolic murmur timing']) else \"\"\n",
    "\n",
    "    if 'Systolic' in systolic_value:\n",
    "        return 'Systolic'\n",
    "    elif 'Diastolic' in diastolic_value:\n",
    "        return 'Diastolic'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "\n",
    "# Now define target_labels using the updated get_murmur_type\n",
    "target_labels = {\n",
    "    index: {\n",
    "        'Murmur Present': True if row['Murmur'] == 'Present' else False,\n",
    "        'Severity': row['Systolic murmur grading'],\n",
    "        'Type': get_murmur_type(row),\n",
    "        'Most Audible Location': row['Most audible location'],\n",
    "    }\n",
    "    for index, row in df.iterrows()\n",
    "}\n",
    "\n",
    "\n",
    "# Check the result for the first patient\n",
    "print(\"First patient sentence embeddings:\", patient_embeddings[0])\n",
    "print(\"First patient target labels:\", target_labels[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9c73408-89a7-4fa8-b774-1384b3028827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patients in patient_embeddings: 942\n",
      "Number of patients in target_labels: 942\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of patients in patient_embeddings: {len(patient_embeddings)}\")\n",
    "print(f\"Number of patients in target_labels: {len(target_labels)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b273638c-2202-4e2e-b4da-5195a5579a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (942, 3)\n",
      "y shape: (942,)\n",
      "First embedding: [0.04833333 0.07666667 0.105     ]\n",
      "First target label: True\n"
     ]
    }
   ],
   "source": [
    "# Aggregate sentence embeddings for each patient by averaging\n",
    "X = np.array([np.mean(patient_embedding_list, axis=0) for patient_embedding_list in patient_embeddings.values()])\n",
    "\n",
    "# Now X should have the shape (942, 3) where 942 is the number of patients and 3 is the embedding size\n",
    "y_murmur_present = np.array([label['Murmur Present'] for label in target_labels.values()])\n",
    "y_severity = np.array([label['Severity'] for label in target_labels.values()])\n",
    "y_type = np.array([label['Type'] for label in target_labels.values()])\n",
    "y_most_audible_location = np.array([label['Most Audible Location'] for label in target_labels.values()])\n",
    "\n",
    "# Check the shapes\n",
    "print(f\"X shape: {X.shape}\")  # Should be (942, 3)\n",
    "print(f\"y shape: {y_murmur_present.shape}\")  # Should be (942,)\n",
    "# Check the first embedding and label\n",
    "print(\"First embedding:\", X[0])\n",
    "print(\"First target label:\", y_murmur_present[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f57c1ded-9019-4a07-94be-629c5ed5c4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have sentence embeddings for each patient\n",
    "# Flatten sentence embeddings into sequences for each patient\n",
    "# Example: sentences -> [[sentence1_embedding, sentence2_embedding], [sentence1_embedding, sentence2_embedding]]\n",
    "\n",
    "X = np.array([embedding for patient_embedding_list in patient_embeddings.values() for embedding in patient_embedding_list])\n",
    "\n",
    "# Padding sequences to make sure each patient has the same number of sentence embeddings\n",
    "X_pad = pad_sequences(X, padding='post', dtype='float32')\n",
    "\n",
    "# Y labels\n",
    "y = np.array([label['Murmur Present'] for label in target_labels.values()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "632d164a-92ef-4b70-acc4-7ed3437b9e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers, models\n",
    "\n",
    "def create_han_model(input_shape):\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Word-Level Bi-LSTM Layer (with return_sequences=True to pass sequences to attention)\n",
    "    word_lstm = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(input_layer)\n",
    "    \n",
    "    # Word-Level Attention Layer\n",
    "    word_attention = layers.Attention(use_scale=True)([word_lstm, word_lstm])\n",
    "    word_attention_output = layers.GlobalAveragePooling1D()(word_attention)\n",
    "\n",
    "    # Document-Level Bi-LSTM Layer (applied to word-level features)\n",
    "    document_lstm = layers.Bidirectional(layers.LSTM(64))(word_attention_output)\n",
    "\n",
    "    # Document-Level Attention Layer\n",
    "    document_attention = layers.Attention(use_scale=True)([document_lstm, document_lstm])\n",
    "\n",
    "    # Output Layer\n",
    "    output = layers.Dense(1, activation='sigmoid')(document_attention)  # Sigmoid for binary classification\n",
    "\n",
    "    model = models.Model(inputs=input_layer, outputs=output)\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "df9d9175-325d-42c0-b3a0-b788ce6ea558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligned X_pad shape: (942, 1, 3)\n",
      "y shape: (942,)\n"
     ]
    }
   ],
   "source": [
    "# Align X_pad to match y\n",
    "X_pad = X_pad[:len(y)]\n",
    "\n",
    "# Verify alignment\n",
    "print(\"Aligned X_pad shape:\", X_pad.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "\n",
    "# Split into training and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_pad, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea022e96-3b23-46af-a66a-4d90f7cb8a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ bidirectional_2               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">135,168</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)               │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ attention_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span> │ bidirectional_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                               │                           │                 │ bidirectional_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_2    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ reshape_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_pooling1d_… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ bidirectional_3               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">164,352</span> │ reshape_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)               │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ attention_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span> │ bidirectional_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                               │                           │                 │ bidirectional_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_3    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">131</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_pooling1d_… │\n",
       "│                               │                           │                 │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,448</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ bidirectional_2               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m135,168\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)               │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ attention_2 (\u001b[38;5;33mAttention\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │               \u001b[38;5;34m1\u001b[0m │ bidirectional_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                               │                           │                 │ bidirectional_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_2    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ attention_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ reshape_1 (\u001b[38;5;33mReshape\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ global_average_pooling1d_… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ bidirectional_3               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m164,352\u001b[0m │ reshape_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)               │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ attention_3 (\u001b[38;5;33mAttention\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │               \u001b[38;5;34m1\u001b[0m │ bidirectional_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                               │                           │                 │ bidirectional_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_3    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ attention_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m131\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ global_average_pooling1d_… │\n",
       "│                               │                           │                 │ input_layer_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m8,448\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │              \u001b[38;5;34m65\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">308,035</span> (1.18 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m308,035\u001b[0m (1.18 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">308,035</span> (1.18 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m308,035\u001b[0m (1.18 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def create_han_model(input_shape):\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Word-Level Bi-LSTM Layer with Dropout\n",
    "    word_lstm = layers.Bidirectional(layers.LSTM(128, return_sequences=True, dropout=0.2))(input_layer)\n",
    "    \n",
    "    # Word-Level Attention Layer\n",
    "    word_attention = layers.Attention(use_scale=True)([word_lstm, word_lstm])\n",
    "    word_attention_output = layers.GlobalAveragePooling1D()(word_attention)\n",
    "\n",
    "    # Document-Level Bi-LSTM Layer with Dropout\n",
    "    document_lstm = layers.Bidirectional(layers.LSTM(64, return_sequences=True, dropout=0.2))(layers.Reshape((1, word_attention_output.shape[-1]))(word_attention_output))\n",
    "\n",
    "    # Document-Level Attention Layer\n",
    "    document_attention = layers.Attention(use_scale=True)([document_lstm, document_lstm])\n",
    "    document_attention_output = layers.GlobalAveragePooling1D()(document_attention)\n",
    "\n",
    "    # Structured Data Input\n",
    "    structured_input = layers.Input(shape=(X_pad.shape[-1],))\n",
    "\n",
    "    # Combine HAN and Structured Data\n",
    "    combined = layers.concatenate([document_attention_output, structured_input])\n",
    "    combined_output = layers.Dense(64, activation='relu')(combined)\n",
    "    combined_output = layers.Dropout(0.2)(combined_output)\n",
    "    \n",
    "    # Output Layer for Binary Classification\n",
    "    output = layers.Dense(1, activation='sigmoid')(combined_output)\n",
    "    \n",
    "    model = models.Model(inputs=[input_layer, structured_input], outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "input_shape = (1, 3)  # Adjust input shape based on your embeddings\n",
    "model = create_han_model(input_shape)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "94ed7085-0a5f-49f9-ad0b-38daea492b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_10\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_10\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ bidirectional_22              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">135,168</span> │ input_layer_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)               │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_26        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ bidirectional_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ attention_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span> │ batch_normalization_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                               │                           │                 │ batch_normalization_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_22   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ reshape_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_pooling1d_… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ bidirectional_23              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">164,352</span> │ reshape_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)               │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_27        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ bidirectional_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ attention_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span> │ batch_normalization_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                               │                           │                 │ batch_normalization_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_23   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ input_layer_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">131</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_pooling1d_… │\n",
       "│                               │                           │                 │ input_layer_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,896</span> │ concatenate_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_28        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dense_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_29        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dense_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dropout_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_30        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ dense_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ dropout_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_21 (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ bidirectional_22              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m135,168\u001b[0m │ input_layer_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)               │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_26        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │           \u001b[38;5;34m1,024\u001b[0m │ bidirectional_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ attention_22 (\u001b[38;5;33mAttention\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │               \u001b[38;5;34m1\u001b[0m │ batch_normalization_26[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                               │                           │                 │ batch_normalization_26[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_22   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ attention_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ reshape_11 (\u001b[38;5;33mReshape\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ global_average_pooling1d_… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ bidirectional_23              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m164,352\u001b[0m │ reshape_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)               │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_27        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m512\u001b[0m │ bidirectional_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ attention_23 (\u001b[38;5;33mAttention\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │               \u001b[38;5;34m1\u001b[0m │ batch_normalization_27[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                               │                           │                 │ batch_normalization_27[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_23   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ attention_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ input_layer_22 (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_10 (\u001b[38;5;33mConcatenate\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m131\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ global_average_pooling1d_… │\n",
       "│                               │                           │                 │ input_layer_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m16,896\u001b[0m │ concatenate_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_28        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │             \u001b[38;5;34m512\u001b[0m │ dense_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_14 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_28[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m8,256\u001b[0m │ dropout_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_29        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │             \u001b[38;5;34m256\u001b[0m │ dense_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_15 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_29[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │           \u001b[38;5;34m2,080\u001b[0m │ dropout_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_30        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │             \u001b[38;5;34m128\u001b[0m │ dense_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_16 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_30[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_27 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │              \u001b[38;5;34m33\u001b[0m │ dropout_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">329,219</span> (1.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m329,219\u001b[0m (1.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">328,003</span> (1.25 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m328,003\u001b[0m (1.25 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,216</span> (4.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,216\u001b[0m (4.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nidhi\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\nn.py:827: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 220ms/step - accuracy: 0.5066 - loss: 8.3776 - val_accuracy: 0.8092 - val_loss: 7.3738 - learning_rate: 0.0010\n",
      "Epoch 2/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.5226 - loss: 7.3283 - val_accuracy: 0.8092 - val_loss: 6.4550 - learning_rate: 0.0010\n",
      "Epoch 3/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.5118 - loss: 6.4780 - val_accuracy: 0.8092 - val_loss: 5.7125 - learning_rate: 0.0010\n",
      "Epoch 4/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.5410 - loss: 5.7299 - val_accuracy: 0.8092 - val_loss: 5.1066 - learning_rate: 0.0010\n",
      "Epoch 5/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.5902 - loss: 5.1511 - val_accuracy: 0.8092 - val_loss: 4.6247 - learning_rate: 0.0010\n",
      "Epoch 6/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.6025 - loss: 4.6293 - val_accuracy: 0.8092 - val_loss: 4.2355 - learning_rate: 0.0010\n",
      "Epoch 7/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.6260 - loss: 4.2859 - val_accuracy: 0.8092 - val_loss: 3.9228 - learning_rate: 0.0010\n",
      "Epoch 8/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6175 - loss: 4.0111 - val_accuracy: 0.8092 - val_loss: 3.6656 - learning_rate: 0.0010\n",
      "Epoch 9/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.6132 - loss: 3.7189 - val_accuracy: 0.8092 - val_loss: 3.4445 - learning_rate: 0.0010\n",
      "Epoch 10/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.6785 - loss: 3.4729 - val_accuracy: 0.8092 - val_loss: 3.2544 - learning_rate: 0.0010\n",
      "Epoch 11/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.6793 - loss: 3.3248 - val_accuracy: 0.8092 - val_loss: 3.0906 - learning_rate: 0.0010\n",
      "Epoch 12/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.7189 - loss: 3.1165 - val_accuracy: 0.8092 - val_loss: 2.9450 - learning_rate: 0.0010\n",
      "Epoch 13/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.6784 - loss: 3.0208 - val_accuracy: 0.8092 - val_loss: 2.8135 - learning_rate: 0.0010\n",
      "Epoch 14/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.7612 - loss: 2.8602 - val_accuracy: 0.8092 - val_loss: 2.6968 - learning_rate: 0.0010\n",
      "Epoch 15/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.7143 - loss: 2.7503 - val_accuracy: 0.8092 - val_loss: 2.5879 - learning_rate: 0.0010\n",
      "Epoch 16/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.7512 - loss: 2.6243 - val_accuracy: 0.8092 - val_loss: 2.4813 - learning_rate: 0.0010\n",
      "Epoch 17/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.7119 - loss: 2.5240 - val_accuracy: 0.8092 - val_loss: 2.3886 - learning_rate: 0.0010\n",
      "Epoch 18/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.7367 - loss: 2.4233 - val_accuracy: 0.8092 - val_loss: 2.2966 - learning_rate: 0.0010\n",
      "Epoch 19/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7509 - loss: 2.3602 - val_accuracy: 0.8092 - val_loss: 2.2101 - learning_rate: 0.0010\n",
      "Epoch 20/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.7740 - loss: 2.2375 - val_accuracy: 0.8092 - val_loss: 2.1282 - learning_rate: 0.0010\n",
      "Epoch 21/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.7728 - loss: 2.1511 - val_accuracy: 0.8092 - val_loss: 2.0481 - learning_rate: 0.0010\n",
      "Epoch 22/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7814 - loss: 2.0874 - val_accuracy: 0.8092 - val_loss: 1.9682 - learning_rate: 0.0010\n",
      "Epoch 23/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7974 - loss: 1.9820 - val_accuracy: 0.8092 - val_loss: 1.8963 - learning_rate: 0.0010\n",
      "Epoch 24/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.7904 - loss: 1.9292 - val_accuracy: 0.8092 - val_loss: 1.8251 - learning_rate: 0.0010\n",
      "Epoch 25/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.7550 - loss: 1.8810 - val_accuracy: 0.8092 - val_loss: 1.7591 - learning_rate: 0.0010\n",
      "Epoch 26/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.7548 - loss: 1.8173 - val_accuracy: 0.8092 - val_loss: 1.6989 - learning_rate: 0.0010\n",
      "Epoch 27/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.7873 - loss: 1.7074 - val_accuracy: 0.8092 - val_loss: 1.6381 - learning_rate: 0.0010\n",
      "Epoch 28/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.7736 - loss: 1.6574 - val_accuracy: 0.8092 - val_loss: 1.5811 - learning_rate: 0.0010\n",
      "Epoch 29/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.7972 - loss: 1.6005 - val_accuracy: 0.8092 - val_loss: 1.5259 - learning_rate: 0.0010\n",
      "Epoch 30/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.7955 - loss: 1.5576 - val_accuracy: 0.8092 - val_loss: 1.4756 - learning_rate: 0.0010\n",
      "Epoch 31/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.7880 - loss: 1.4948 - val_accuracy: 0.8092 - val_loss: 1.4263 - learning_rate: 0.0010\n",
      "Epoch 32/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.7799 - loss: 1.4736 - val_accuracy: 0.8092 - val_loss: 1.3820 - learning_rate: 0.0010\n",
      "Epoch 33/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.7945 - loss: 1.3878 - val_accuracy: 0.8092 - val_loss: 1.3397 - learning_rate: 0.0010\n",
      "Epoch 34/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.7995 - loss: 1.3554 - val_accuracy: 0.8092 - val_loss: 1.2973 - learning_rate: 0.0010\n",
      "Epoch 35/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8144 - loss: 1.3127 - val_accuracy: 0.8092 - val_loss: 1.2584 - learning_rate: 0.0010\n",
      "Epoch 36/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.7878 - loss: 1.3095 - val_accuracy: 0.8092 - val_loss: 1.2216 - learning_rate: 0.0010\n",
      "Epoch 37/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8031 - loss: 1.2404 - val_accuracy: 0.8092 - val_loss: 1.1871 - learning_rate: 0.0010\n",
      "Epoch 38/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.7878 - loss: 1.2247 - val_accuracy: 0.8092 - val_loss: 1.1545 - learning_rate: 0.0010\n",
      "Epoch 39/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8001 - loss: 1.1691 - val_accuracy: 0.8092 - val_loss: 1.1243 - learning_rate: 0.0010\n",
      "Epoch 40/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.7959 - loss: 1.1321 - val_accuracy: 0.8092 - val_loss: 1.0954 - learning_rate: 0.0010\n",
      "Epoch 41/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.7970 - loss: 1.1048 - val_accuracy: 0.8092 - val_loss: 1.0678 - learning_rate: 0.0010\n",
      "Epoch 42/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.8126 - loss: 1.0949 - val_accuracy: 0.8092 - val_loss: 1.0419 - learning_rate: 0.0010\n",
      "Epoch 43/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.8051 - loss: 1.0331 - val_accuracy: 0.8092 - val_loss: 1.0178 - learning_rate: 0.0010\n",
      "Epoch 44/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7965 - loss: 1.0560 - val_accuracy: 0.8092 - val_loss: 0.9943 - learning_rate: 0.0010\n",
      "Epoch 45/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7964 - loss: 1.0318 - val_accuracy: 0.8092 - val_loss: 0.9718 - learning_rate: 0.0010\n",
      "Epoch 46/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.7948 - loss: 0.9842 - val_accuracy: 0.8092 - val_loss: 0.9492 - learning_rate: 0.0010\n",
      "Epoch 47/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8028 - loss: 0.9253 - val_accuracy: 0.8092 - val_loss: 0.9272 - learning_rate: 0.0010\n",
      "Epoch 48/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.8011 - loss: 0.9684 - val_accuracy: 0.8092 - val_loss: 0.9069 - learning_rate: 0.0010\n",
      "Epoch 49/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.8219 - loss: 0.8984 - val_accuracy: 0.8092 - val_loss: 0.8903 - learning_rate: 0.0010\n",
      "Epoch 50/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8080 - loss: 0.8969 - val_accuracy: 0.8092 - val_loss: 0.8724 - learning_rate: 0.0010\n",
      "Epoch 51/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.7863 - loss: 0.9085 - val_accuracy: 0.8092 - val_loss: 0.8521 - learning_rate: 0.0010\n",
      "Epoch 52/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8066 - loss: 0.8603 - val_accuracy: 0.8092 - val_loss: 0.8349 - learning_rate: 0.0010\n",
      "Epoch 53/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7905 - loss: 0.8629 - val_accuracy: 0.8092 - val_loss: 0.8194 - learning_rate: 0.0010\n",
      "Epoch 54/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.7922 - loss: 0.8614 - val_accuracy: 0.8092 - val_loss: 0.8045 - learning_rate: 0.0010\n",
      "Epoch 55/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.7926 - loss: 0.8345 - val_accuracy: 0.8092 - val_loss: 0.7909 - learning_rate: 0.0010\n",
      "Epoch 56/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8180 - loss: 0.7861 - val_accuracy: 0.8092 - val_loss: 0.7773 - learning_rate: 0.0010\n",
      "Epoch 57/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8046 - loss: 0.7807 - val_accuracy: 0.8092 - val_loss: 0.7646 - learning_rate: 0.0010\n",
      "Epoch 58/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.8094 - loss: 0.7866 - val_accuracy: 0.8092 - val_loss: 0.7524 - learning_rate: 0.0010\n",
      "Epoch 59/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.8185 - loss: 0.7354 - val_accuracy: 0.8092 - val_loss: 0.7410 - learning_rate: 0.0010\n",
      "Epoch 60/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7958 - loss: 0.7587 - val_accuracy: 0.8092 - val_loss: 0.7304 - learning_rate: 0.0010\n",
      "Epoch 61/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8185 - loss: 0.7274 - val_accuracy: 0.8092 - val_loss: 0.7205 - learning_rate: 0.0010\n",
      "Epoch 62/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8042 - loss: 0.7206 - val_accuracy: 0.8092 - val_loss: 0.7113 - learning_rate: 0.0010\n",
      "Epoch 63/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8208 - loss: 0.7209 - val_accuracy: 0.8092 - val_loss: 0.7030 - learning_rate: 0.0010\n",
      "Epoch 64/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.8029 - loss: 0.7108 - val_accuracy: 0.8092 - val_loss: 0.6940 - learning_rate: 0.0010\n",
      "Epoch 65/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.7951 - loss: 0.7063 - val_accuracy: 0.8092 - val_loss: 0.6854 - learning_rate: 0.0010\n",
      "Epoch 66/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.7955 - loss: 0.7273 - val_accuracy: 0.8092 - val_loss: 0.6777 - learning_rate: 0.0010\n",
      "Epoch 67/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.8153 - loss: 0.6856 - val_accuracy: 0.8092 - val_loss: 0.6708 - learning_rate: 0.0010\n",
      "Epoch 68/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.8038 - loss: 0.6905 - val_accuracy: 0.8092 - val_loss: 0.6644 - learning_rate: 0.0010\n",
      "Epoch 69/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.8025 - loss: 0.6759 - val_accuracy: 0.8092 - val_loss: 0.6574 - learning_rate: 0.0010\n",
      "Epoch 70/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8053 - loss: 0.6745 - val_accuracy: 0.8092 - val_loss: 0.6523 - learning_rate: 0.0010\n",
      "Epoch 71/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7833 - loss: 0.6910 - val_accuracy: 0.8092 - val_loss: 0.6464 - learning_rate: 0.0010\n",
      "Epoch 72/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8140 - loss: 0.6503 - val_accuracy: 0.8092 - val_loss: 0.6401 - learning_rate: 0.0010\n",
      "Epoch 73/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.8256 - loss: 0.6226 - val_accuracy: 0.8092 - val_loss: 0.6341 - learning_rate: 0.0010\n",
      "Epoch 74/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8194 - loss: 0.6359 - val_accuracy: 0.8092 - val_loss: 0.6281 - learning_rate: 0.0010\n",
      "Epoch 75/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8211 - loss: 0.6261 - val_accuracy: 0.8092 - val_loss: 0.6227 - learning_rate: 0.0010\n",
      "Epoch 76/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7977 - loss: 0.6425 - val_accuracy: 0.8092 - val_loss: 0.6189 - learning_rate: 0.0010\n",
      "Epoch 77/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8159 - loss: 0.6170 - val_accuracy: 0.8092 - val_loss: 0.6148 - learning_rate: 0.0010\n",
      "Epoch 78/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8166 - loss: 0.6072 - val_accuracy: 0.8092 - val_loss: 0.6092 - learning_rate: 0.0010\n",
      "Epoch 79/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.7984 - loss: 0.6350 - val_accuracy: 0.8092 - val_loss: 0.6045 - learning_rate: 0.0010\n",
      "Epoch 80/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.7842 - loss: 0.6522 - val_accuracy: 0.8092 - val_loss: 0.6010 - learning_rate: 0.0010\n",
      "Epoch 81/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.7970 - loss: 0.6214 - val_accuracy: 0.8092 - val_loss: 0.5982 - learning_rate: 0.0010\n",
      "Epoch 82/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.7926 - loss: 0.6446 - val_accuracy: 0.8092 - val_loss: 0.5942 - learning_rate: 0.0010\n",
      "Epoch 83/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.7929 - loss: 0.6318 - val_accuracy: 0.8092 - val_loss: 0.5907 - learning_rate: 0.0010\n",
      "Epoch 84/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.7897 - loss: 0.6227 - val_accuracy: 0.8092 - val_loss: 0.5880 - learning_rate: 0.0010\n",
      "Epoch 85/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7930 - loss: 0.6153 - val_accuracy: 0.8092 - val_loss: 0.5844 - learning_rate: 0.0010\n",
      "Epoch 86/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.7927 - loss: 0.6095 - val_accuracy: 0.8092 - val_loss: 0.5814 - learning_rate: 0.0010\n",
      "Epoch 87/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.7998 - loss: 0.5959 - val_accuracy: 0.8092 - val_loss: 0.5782 - learning_rate: 0.0010\n",
      "Epoch 88/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.8024 - loss: 0.5990 - val_accuracy: 0.8092 - val_loss: 0.5757 - learning_rate: 0.0010\n",
      "Epoch 89/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.8180 - loss: 0.5923 - val_accuracy: 0.8092 - val_loss: 0.5723 - learning_rate: 0.0010\n",
      "Epoch 90/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.8184 - loss: 0.5664 - val_accuracy: 0.8092 - val_loss: 0.5696 - learning_rate: 0.0010\n",
      "Epoch 91/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8052 - loss: 0.5823 - val_accuracy: 0.8092 - val_loss: 0.5672 - learning_rate: 0.0010\n",
      "Epoch 92/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8122 - loss: 0.5675 - val_accuracy: 0.8092 - val_loss: 0.5648 - learning_rate: 0.0010\n",
      "Epoch 93/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.7939 - loss: 0.5887 - val_accuracy: 0.8092 - val_loss: 0.5625 - learning_rate: 0.0010\n",
      "Epoch 94/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8061 - loss: 0.5857 - val_accuracy: 0.8092 - val_loss: 0.5620 - learning_rate: 0.0010\n",
      "Epoch 95/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.8108 - loss: 0.5573 - val_accuracy: 0.8092 - val_loss: 0.5610 - learning_rate: 0.0010\n",
      "Epoch 96/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.8036 - loss: 0.5702 - val_accuracy: 0.8092 - val_loss: 0.5590 - learning_rate: 0.0010\n",
      "Epoch 97/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.8002 - loss: 0.5737 - val_accuracy: 0.8092 - val_loss: 0.5571 - learning_rate: 0.0010\n",
      "Epoch 98/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8328 - loss: 0.5280 - val_accuracy: 0.8092 - val_loss: 0.5548 - learning_rate: 0.0010\n",
      "Epoch 99/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.7982 - loss: 0.5719 - val_accuracy: 0.8092 - val_loss: 0.5529 - learning_rate: 0.0010\n",
      "Epoch 100/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8049 - loss: 0.5959 - val_accuracy: 0.8092 - val_loss: 0.5519 - learning_rate: 0.0010\n",
      "Epoch 101/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.8050 - loss: 0.5734 - val_accuracy: 0.8092 - val_loss: 0.5497 - learning_rate: 0.0010\n",
      "Epoch 102/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.8032 - loss: 0.5633 - val_accuracy: 0.8092 - val_loss: 0.5484 - learning_rate: 0.0010\n",
      "Epoch 103/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.8237 - loss: 0.5263 - val_accuracy: 0.8092 - val_loss: 0.5473 - learning_rate: 0.0010\n",
      "Epoch 104/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8226 - loss: 0.5339 - val_accuracy: 0.8092 - val_loss: 0.5458 - learning_rate: 0.0010\n",
      "Epoch 105/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8057 - loss: 0.5618 - val_accuracy: 0.8092 - val_loss: 0.5421 - learning_rate: 0.0010\n",
      "Epoch 106/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8271 - loss: 0.5177 - val_accuracy: 0.8092 - val_loss: 0.5404 - learning_rate: 0.0010\n",
      "Epoch 107/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8032 - loss: 0.5477 - val_accuracy: 0.8092 - val_loss: 0.5402 - learning_rate: 0.0010\n",
      "Epoch 108/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.7921 - loss: 0.5659 - val_accuracy: 0.8092 - val_loss: 0.5376 - learning_rate: 0.0010\n",
      "Epoch 109/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8179 - loss: 0.5271 - val_accuracy: 0.8092 - val_loss: 0.5356 - learning_rate: 0.0010\n",
      "Epoch 110/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.7863 - loss: 0.5669 - val_accuracy: 0.8092 - val_loss: 0.5333 - learning_rate: 0.0010\n",
      "Epoch 111/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.8105 - loss: 0.5313 - val_accuracy: 0.8092 - val_loss: 0.5315 - learning_rate: 0.0010\n",
      "Epoch 112/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7849 - loss: 0.5637 - val_accuracy: 0.8092 - val_loss: 0.5297 - learning_rate: 0.0010\n",
      "Epoch 113/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8100 - loss: 0.5276 - val_accuracy: 0.8092 - val_loss: 0.5286 - learning_rate: 0.0010\n",
      "Epoch 114/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.7935 - loss: 0.5535 - val_accuracy: 0.8092 - val_loss: 0.5277 - learning_rate: 0.0010\n",
      "Epoch 115/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.8107 - loss: 0.5251 - val_accuracy: 0.8092 - val_loss: 0.5265 - learning_rate: 0.0010\n",
      "Epoch 116/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8092 - loss: 0.5431 - val_accuracy: 0.8092 - val_loss: 0.5259 - learning_rate: 0.0010\n",
      "Epoch 117/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.8158 - loss: 0.5225 - val_accuracy: 0.8092 - val_loss: 0.5244 - learning_rate: 0.0010\n",
      "Epoch 118/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8045 - loss: 0.5414 - val_accuracy: 0.8092 - val_loss: 0.5236 - learning_rate: 0.0010\n",
      "Epoch 119/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8054 - loss: 0.5385 - val_accuracy: 0.8092 - val_loss: 0.5232 - learning_rate: 0.0010\n",
      "Epoch 120/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8109 - loss: 0.5216 - val_accuracy: 0.8092 - val_loss: 0.5219 - learning_rate: 0.0010\n",
      "Epoch 121/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8178 - loss: 0.5143 - val_accuracy: 0.8092 - val_loss: 0.5203 - learning_rate: 0.0010\n",
      "Epoch 122/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8174 - loss: 0.5187 - val_accuracy: 0.8092 - val_loss: 0.5191 - learning_rate: 0.0010\n",
      "Epoch 123/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8113 - loss: 0.5240 - val_accuracy: 0.8092 - val_loss: 0.5183 - learning_rate: 0.0010\n",
      "Epoch 124/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8234 - loss: 0.5019 - val_accuracy: 0.8092 - val_loss: 0.5174 - learning_rate: 0.0010\n",
      "Epoch 125/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7966 - loss: 0.5453 - val_accuracy: 0.8092 - val_loss: 0.5168 - learning_rate: 0.0010\n",
      "Epoch 126/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.7760 - loss: 0.5652 - val_accuracy: 0.8092 - val_loss: 0.5168 - learning_rate: 0.0010\n",
      "Epoch 127/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8017 - loss: 0.5458 - val_accuracy: 0.8092 - val_loss: 0.5163 - learning_rate: 0.0010\n",
      "Epoch 128/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8154 - loss: 0.5034 - val_accuracy: 0.8092 - val_loss: 0.5163 - learning_rate: 0.0010\n",
      "Epoch 129/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.7987 - loss: 0.5264 - val_accuracy: 0.8092 - val_loss: 0.5159 - learning_rate: 0.0010\n",
      "Epoch 130/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.8076 - loss: 0.5195 - val_accuracy: 0.8092 - val_loss: 0.5154 - learning_rate: 0.0010\n",
      "Epoch 131/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8214 - loss: 0.5117 - val_accuracy: 0.8092 - val_loss: 0.5153 - learning_rate: 0.0010\n",
      "Epoch 132/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8114 - loss: 0.5223 - val_accuracy: 0.8092 - val_loss: 0.5147 - learning_rate: 0.0010\n",
      "Epoch 133/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.8239 - loss: 0.5032 - val_accuracy: 0.8092 - val_loss: 0.5137 - learning_rate: 0.0010\n",
      "Epoch 134/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.8065 - loss: 0.5300 - val_accuracy: 0.8092 - val_loss: 0.5126 - learning_rate: 0.0010\n",
      "Epoch 135/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.8178 - loss: 0.5056 - val_accuracy: 0.8092 - val_loss: 0.5122 - learning_rate: 0.0010\n",
      "Epoch 136/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8080 - loss: 0.5204 - val_accuracy: 0.8092 - val_loss: 0.5130 - learning_rate: 0.0010\n",
      "Epoch 137/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8320 - loss: 0.4911 - val_accuracy: 0.8092 - val_loss: 0.5129 - learning_rate: 0.0010\n",
      "Epoch 138/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.8192 - loss: 0.4986 - val_accuracy: 0.8092 - val_loss: 0.5122 - learning_rate: 0.0010\n",
      "Epoch 139/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8309 - loss: 0.4872 - val_accuracy: 0.8092 - val_loss: 0.5131 - learning_rate: 0.0010\n",
      "Epoch 140/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.7938 - loss: 0.5453 - val_accuracy: 0.8092 - val_loss: 0.5147 - learning_rate: 0.0010\n",
      "Epoch 141/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8236 - loss: 0.4948 - val_accuracy: 0.8092 - val_loss: 0.5125 - learning_rate: 0.0010\n",
      "Epoch 142/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8085 - loss: 0.5202 - val_accuracy: 0.8092 - val_loss: 0.5108 - learning_rate: 0.0010\n",
      "Epoch 143/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.7934 - loss: 0.5390 - val_accuracy: 0.8092 - val_loss: 0.5101 - learning_rate: 0.0010\n",
      "Epoch 144/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8093 - loss: 0.5174 - val_accuracy: 0.8092 - val_loss: 0.5120 - learning_rate: 0.0010\n",
      "Epoch 145/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.8125 - loss: 0.5066 - val_accuracy: 0.8092 - val_loss: 0.5124 - learning_rate: 0.0010\n",
      "Epoch 146/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8076 - loss: 0.5333 - val_accuracy: 0.8092 - val_loss: 0.5095 - learning_rate: 0.0010\n",
      "Epoch 147/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8159 - loss: 0.4980 - val_accuracy: 0.8092 - val_loss: 0.5095 - learning_rate: 0.0010\n",
      "Epoch 148/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.8256 - loss: 0.4944 - val_accuracy: 0.8092 - val_loss: 0.5092 - learning_rate: 0.0010\n",
      "Epoch 149/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8133 - loss: 0.5064 - val_accuracy: 0.8092 - val_loss: 0.5093 - learning_rate: 0.0010\n",
      "Epoch 150/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8283 - loss: 0.4964 - val_accuracy: 0.8092 - val_loss: 0.5090 - learning_rate: 0.0010\n",
      "Epoch 151/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8098 - loss: 0.5154 - val_accuracy: 0.8092 - val_loss: 0.5093 - learning_rate: 0.0010\n",
      "Epoch 152/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.8200 - loss: 0.4944 - val_accuracy: 0.8092 - val_loss: 0.5100 - learning_rate: 0.0010\n",
      "Epoch 153/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8019 - loss: 0.5179 - val_accuracy: 0.8092 - val_loss: 0.5115 - learning_rate: 0.0010\n",
      "Epoch 154/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8066 - loss: 0.5215 - val_accuracy: 0.8092 - val_loss: 0.5156 - learning_rate: 0.0010\n",
      "Epoch 155/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8075 - loss: 0.5049 - val_accuracy: 0.8092 - val_loss: 0.5177 - learning_rate: 0.0010\n",
      "Epoch 156/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.7918 - loss: 0.5455 - val_accuracy: 0.8092 - val_loss: 0.5140 - learning_rate: 0.0010\n",
      "Epoch 157/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.8048 - loss: 0.5232 - val_accuracy: 0.8092 - val_loss: 0.5117 - learning_rate: 0.0010\n",
      "Epoch 158/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.8275 - loss: 0.4899 - val_accuracy: 0.8092 - val_loss: 0.5104 - learning_rate: 0.0010\n",
      "Epoch 159/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8014 - loss: 0.5319 - val_accuracy: 0.8092 - val_loss: 0.5093 - learning_rate: 0.0010\n",
      "Epoch 160/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.7895 - loss: 0.5407 - val_accuracy: 0.8092 - val_loss: 0.5068 - learning_rate: 0.0010\n",
      "Epoch 161/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8028 - loss: 0.5224 - val_accuracy: 0.8092 - val_loss: 0.5073 - learning_rate: 0.0010\n",
      "Epoch 162/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8161 - loss: 0.4952 - val_accuracy: 0.8092 - val_loss: 0.5068 - learning_rate: 0.0010\n",
      "Epoch 163/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8308 - loss: 0.4786 - val_accuracy: 0.8092 - val_loss: 0.5061 - learning_rate: 0.0010\n",
      "Epoch 164/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8007 - loss: 0.5238 - val_accuracy: 0.8092 - val_loss: 0.5056 - learning_rate: 0.0010\n",
      "Epoch 165/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8176 - loss: 0.5004 - val_accuracy: 0.8092 - val_loss: 0.5049 - learning_rate: 0.0010\n",
      "Epoch 166/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7917 - loss: 0.5310 - val_accuracy: 0.8092 - val_loss: 0.5047 - learning_rate: 0.0010\n",
      "Epoch 167/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8264 - loss: 0.4956 - val_accuracy: 0.8092 - val_loss: 0.5045 - learning_rate: 0.0010\n",
      "Epoch 168/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.8046 - loss: 0.5099 - val_accuracy: 0.8092 - val_loss: 0.5042 - learning_rate: 0.0010\n",
      "Epoch 169/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.8053 - loss: 0.5038 - val_accuracy: 0.8092 - val_loss: 0.5036 - learning_rate: 0.0010\n",
      "Epoch 170/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.8070 - loss: 0.5137 - val_accuracy: 0.8092 - val_loss: 0.5033 - learning_rate: 0.0010\n",
      "Epoch 171/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8175 - loss: 0.5002 - val_accuracy: 0.8092 - val_loss: 0.5084 - learning_rate: 0.0010\n",
      "Epoch 172/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8231 - loss: 0.4868 - val_accuracy: 0.8092 - val_loss: 0.5059 - learning_rate: 0.0010\n",
      "Epoch 173/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8036 - loss: 0.5192 - val_accuracy: 0.8092 - val_loss: 0.5034 - learning_rate: 0.0010\n",
      "Epoch 174/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.8107 - loss: 0.5011 - val_accuracy: 0.8092 - val_loss: 0.5030 - learning_rate: 0.0010\n",
      "Epoch 175/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8055 - loss: 0.5051 - val_accuracy: 0.8092 - val_loss: 0.5023 - learning_rate: 0.0010\n",
      "Epoch 176/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.8045 - loss: 0.5127 - val_accuracy: 0.8092 - val_loss: 0.5024 - learning_rate: 0.0010\n",
      "Epoch 177/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7983 - loss: 0.5153 - val_accuracy: 0.8092 - val_loss: 0.5026 - learning_rate: 0.0010\n",
      "Epoch 178/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8161 - loss: 0.4905 - val_accuracy: 0.8092 - val_loss: 0.5025 - learning_rate: 0.0010\n",
      "Epoch 179/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7901 - loss: 0.5429 - val_accuracy: 0.8092 - val_loss: 0.5020 - learning_rate: 0.0010\n",
      "Epoch 180/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8148 - loss: 0.4991 - val_accuracy: 0.8092 - val_loss: 0.5017 - learning_rate: 0.0010\n",
      "Epoch 181/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8071 - loss: 0.5075 - val_accuracy: 0.8092 - val_loss: 0.5019 - learning_rate: 0.0010\n",
      "Epoch 182/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8077 - loss: 0.5197 - val_accuracy: 0.8092 - val_loss: 0.5015 - learning_rate: 0.0010\n",
      "Epoch 183/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8186 - loss: 0.4935 - val_accuracy: 0.8092 - val_loss: 0.5015 - learning_rate: 0.0010\n",
      "Epoch 184/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8049 - loss: 0.5231 - val_accuracy: 0.8092 - val_loss: 0.5014 - learning_rate: 0.0010\n",
      "Epoch 185/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8156 - loss: 0.5049 - val_accuracy: 0.8092 - val_loss: 0.5017 - learning_rate: 0.0010\n",
      "Epoch 186/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.8008 - loss: 0.5154 - val_accuracy: 0.8092 - val_loss: 0.5019 - learning_rate: 0.0010\n",
      "Epoch 187/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8243 - loss: 0.4897 - val_accuracy: 0.8092 - val_loss: 0.5009 - learning_rate: 0.0010\n",
      "Epoch 188/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8120 - loss: 0.4998 - val_accuracy: 0.8092 - val_loss: 0.4999 - learning_rate: 0.0010\n",
      "Epoch 189/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.7981 - loss: 0.5177 - val_accuracy: 0.8092 - val_loss: 0.4994 - learning_rate: 0.0010\n",
      "Epoch 190/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.8076 - loss: 0.5010 - val_accuracy: 0.8092 - val_loss: 0.4997 - learning_rate: 0.0010\n",
      "Epoch 191/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8207 - loss: 0.4848 - val_accuracy: 0.8092 - val_loss: 0.4990 - learning_rate: 0.0010\n",
      "Epoch 192/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.8204 - loss: 0.4809 - val_accuracy: 0.8092 - val_loss: 0.4988 - learning_rate: 0.0010\n",
      "Epoch 193/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.8211 - loss: 0.4932 - val_accuracy: 0.8092 - val_loss: 0.4986 - learning_rate: 0.0010\n",
      "Epoch 194/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.8121 - loss: 0.4975 - val_accuracy: 0.8092 - val_loss: 0.4993 - learning_rate: 0.0010\n",
      "Epoch 195/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.7898 - loss: 0.5242 - val_accuracy: 0.8092 - val_loss: 0.4997 - learning_rate: 0.0010\n",
      "Epoch 196/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.8246 - loss: 0.4728 - val_accuracy: 0.8092 - val_loss: 0.4991 - learning_rate: 0.0010\n",
      "Epoch 197/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8009 - loss: 0.5109 - val_accuracy: 0.8092 - val_loss: 0.4996 - learning_rate: 0.0010\n",
      "Epoch 198/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8066 - loss: 0.5012 - val_accuracy: 0.8092 - val_loss: 0.4988 - learning_rate: 0.0010\n",
      "Epoch 199/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8115 - loss: 0.4931 - val_accuracy: 0.8092 - val_loss: 0.4981 - learning_rate: 0.0010\n",
      "Epoch 200/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.7987 - loss: 0.5212 - val_accuracy: 0.8092 - val_loss: 0.4974 - learning_rate: 0.0010\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8040 - loss: 0.5061\n",
      "Test Loss: 0.49744120240211487\n",
      "Test Accuracy: 0.8091872930526733\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def create_han_model(input_shape):\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Word-Level Bi-LSTM Layer with L2 Regularization and Dropout\n",
    "    word_lstm = layers.Bidirectional(\n",
    "        layers.LSTM(\n",
    "            128,\n",
    "            return_sequences=True,\n",
    "            dropout=0.3,\n",
    "            kernel_regularizer=l2(0.01)\n",
    "        )\n",
    "    )(input_layer)\n",
    "    word_lstm = BatchNormalization()(word_lstm)\n",
    "\n",
    "    # Word-Level Attention Layer\n",
    "    word_attention = layers.Attention(use_scale=True)([word_lstm, word_lstm])\n",
    "    word_attention_output = layers.GlobalAveragePooling1D()(word_attention)\n",
    "\n",
    "    # Document-Level Bi-LSTM Layer with L2 Regularization and Dropout\n",
    "    document_lstm = layers.Bidirectional(\n",
    "        layers.LSTM(\n",
    "            64,\n",
    "            return_sequences=True,\n",
    "            dropout=0.3,\n",
    "            kernel_regularizer=l2(0.01)\n",
    "        )\n",
    "    )(layers.Reshape((1, word_attention_output.shape[-1]))(word_attention_output))\n",
    "    document_lstm = BatchNormalization()(document_lstm)\n",
    "\n",
    "    # Document-Level Attention Layer\n",
    "    document_attention = layers.Attention(use_scale=True)([document_lstm, document_lstm])\n",
    "    document_attention_output = layers.GlobalAveragePooling1D()(document_attention)\n",
    "\n",
    "    # Structured Data Input\n",
    "    structured_input = layers.Input(shape=(X_pad.shape[-1],))\n",
    "\n",
    "    # Combine HAN and Structured Data with Dense Layers\n",
    "    combined = layers.concatenate([document_attention_output, structured_input])\n",
    "\n",
    "    # Add Dense Layers with L2 Regularization\n",
    "    combined_output = layers.Dense(\n",
    "        128, activation='relu', kernel_regularizer=l2(0.01)\n",
    "    )(combined)\n",
    "    combined_output = BatchNormalization()(combined_output)\n",
    "    combined_output = layers.Dropout(0.4)(combined_output)\n",
    "\n",
    "    combined_output = layers.Dense(\n",
    "        64, activation='relu', kernel_regularizer=l2(0.01)\n",
    "    )(combined_output)\n",
    "    combined_output = BatchNormalization()(combined_output)\n",
    "    combined_output = layers.Dropout(0.3)(combined_output)\n",
    "\n",
    "    combined_output = layers.Dense(\n",
    "        32, activation='relu', kernel_regularizer=l2(0.01)\n",
    "    )(combined_output)\n",
    "    combined_output = BatchNormalization()(combined_output)\n",
    "    combined_output = layers.Dropout(0.3)(combined_output)\n",
    "\n",
    "    # Output Layer for Binary Classification\n",
    "    output = layers.Dense(\n",
    "        1, activation='sigmoid', kernel_regularizer=l2(0.01)\n",
    "    )(combined_output)\n",
    "\n",
    "    model = models.Model(inputs=[input_layer, structured_input], outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),  # Adjust learning rate if needed\n",
    "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Define input shape and create the model\n",
    "input_shape = (1, 3)  # Update based on your actual input shape\n",
    "model = create_han_model(input_shape)\n",
    "model.summary()\n",
    "\n",
    "# Split the data into training and testing sets (70:30 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_pad, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Reshape structured inputs to match model expectations\n",
    "structured_input_train = X_train[:, 0, :]\n",
    "structured_input_test = X_test[:, 0, :]\n",
    "\n",
    "# EarlyStopping and ReduceLROnPlateau\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=0.00001)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    [X_train, structured_input_train], y_train,\n",
    "    epochs=200, batch_size=64,\n",
    "    validation_data=([X_test, structured_input_test], y_test),\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate([X_test, structured_input_test], y_test)\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6d2a1d3b-f813-4461-b366-c1b3555c1bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Fold 1/5...\n",
      "Epoch 1/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 115ms/step - accuracy: 0.5054 - loss: 8.1465 - val_accuracy: 0.8042 - val_loss: 6.5039 - learning_rate: 0.0010\n",
      "Epoch 2/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5358 - loss: 6.3002 - val_accuracy: 0.8042 - val_loss: 5.2040 - learning_rate: 0.0010\n",
      "Epoch 3/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5870 - loss: 5.0946 - val_accuracy: 0.8042 - val_loss: 4.3923 - learning_rate: 0.0010\n",
      "Epoch 4/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6418 - loss: 4.3135 - val_accuracy: 0.8042 - val_loss: 3.8710 - learning_rate: 0.0010\n",
      "Epoch 5/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.6779 - loss: 3.8360 - val_accuracy: 0.8042 - val_loss: 3.5028 - learning_rate: 0.0010\n",
      "Epoch 6/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6923 - loss: 3.4620 - val_accuracy: 0.8042 - val_loss: 3.2191 - learning_rate: 0.0010\n",
      "Epoch 7/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7172 - loss: 3.1897 - val_accuracy: 0.8042 - val_loss: 2.9829 - learning_rate: 0.0010\n",
      "Epoch 8/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7120 - loss: 2.9678 - val_accuracy: 0.8042 - val_loss: 2.7821 - learning_rate: 0.0010\n",
      "Epoch 9/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7358 - loss: 2.7752 - val_accuracy: 0.8042 - val_loss: 2.5851 - learning_rate: 0.0010\n",
      "Epoch 10/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7647 - loss: 2.5602 - val_accuracy: 0.8042 - val_loss: 2.4115 - learning_rate: 0.0010\n",
      "Epoch 11/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7403 - loss: 2.4240 - val_accuracy: 0.8042 - val_loss: 2.2591 - learning_rate: 0.0010\n",
      "Epoch 12/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7975 - loss: 2.2362 - val_accuracy: 0.8042 - val_loss: 2.1140 - learning_rate: 0.0010\n",
      "Epoch 13/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7742 - loss: 2.1181 - val_accuracy: 0.8042 - val_loss: 1.9800 - learning_rate: 0.0010\n",
      "Epoch 14/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7837 - loss: 1.9742 - val_accuracy: 0.8042 - val_loss: 1.8556 - learning_rate: 0.0010\n",
      "Epoch 15/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7938 - loss: 1.8593 - val_accuracy: 0.8042 - val_loss: 1.7363 - learning_rate: 0.0010\n",
      "Epoch 16/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7907 - loss: 1.7278 - val_accuracy: 0.8042 - val_loss: 1.6297 - learning_rate: 0.0010\n",
      "Epoch 17/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7877 - loss: 1.6589 - val_accuracy: 0.8042 - val_loss: 1.5358 - learning_rate: 0.0010\n",
      "Epoch 18/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7899 - loss: 1.5380 - val_accuracy: 0.8042 - val_loss: 1.4508 - learning_rate: 0.0010\n",
      "Epoch 19/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7848 - loss: 1.4563 - val_accuracy: 0.8042 - val_loss: 1.3705 - learning_rate: 0.0010\n",
      "Epoch 20/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8177 - loss: 1.3557 - val_accuracy: 0.8042 - val_loss: 1.2990 - learning_rate: 0.0010\n",
      "Epoch 21/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7768 - loss: 1.3301 - val_accuracy: 0.8042 - val_loss: 1.2365 - learning_rate: 0.0010\n",
      "Epoch 22/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7978 - loss: 1.2453 - val_accuracy: 0.8042 - val_loss: 1.1783 - learning_rate: 0.0010\n",
      "Epoch 23/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7930 - loss: 1.1966 - val_accuracy: 0.8042 - val_loss: 1.1225 - learning_rate: 0.0010\n",
      "Epoch 24/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8000 - loss: 1.1189 - val_accuracy: 0.8042 - val_loss: 1.0725 - learning_rate: 0.0010\n",
      "Epoch 25/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7713 - loss: 1.1097 - val_accuracy: 0.8042 - val_loss: 1.0273 - learning_rate: 0.0010\n",
      "Epoch 26/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8243 - loss: 0.9887 - val_accuracy: 0.8042 - val_loss: 0.9828 - learning_rate: 0.0010\n",
      "Epoch 27/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8099 - loss: 0.9783 - val_accuracy: 0.8042 - val_loss: 0.9420 - learning_rate: 0.0010\n",
      "Epoch 28/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8131 - loss: 0.9237 - val_accuracy: 0.8042 - val_loss: 0.9071 - learning_rate: 0.0010\n",
      "Epoch 29/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8033 - loss: 0.8960 - val_accuracy: 0.8042 - val_loss: 0.8761 - learning_rate: 0.0010\n",
      "Epoch 30/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8044 - loss: 0.8700 - val_accuracy: 0.8042 - val_loss: 0.8502 - learning_rate: 0.0010\n",
      "Epoch 31/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8177 - loss: 0.8463 - val_accuracy: 0.8042 - val_loss: 0.8217 - learning_rate: 0.0010\n",
      "Epoch 32/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7798 - loss: 0.8357 - val_accuracy: 0.8042 - val_loss: 0.7947 - learning_rate: 0.0010\n",
      "Epoch 33/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8043 - loss: 0.8018 - val_accuracy: 0.8042 - val_loss: 0.7755 - learning_rate: 0.0010\n",
      "Epoch 34/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8048 - loss: 0.7702 - val_accuracy: 0.8042 - val_loss: 0.7539 - learning_rate: 0.0010\n",
      "Epoch 35/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7986 - loss: 0.7625 - val_accuracy: 0.8042 - val_loss: 0.7353 - learning_rate: 0.0010\n",
      "Epoch 36/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7885 - loss: 0.7547 - val_accuracy: 0.8042 - val_loss: 0.7183 - learning_rate: 0.0010\n",
      "Epoch 37/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8003 - loss: 0.7342 - val_accuracy: 0.8042 - val_loss: 0.7004 - learning_rate: 0.0010\n",
      "Epoch 38/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8040 - loss: 0.6952 - val_accuracy: 0.8042 - val_loss: 0.6867 - learning_rate: 0.0010\n",
      "Epoch 39/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8168 - loss: 0.6536 - val_accuracy: 0.8042 - val_loss: 0.6717 - learning_rate: 0.0010\n",
      "Epoch 40/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8216 - loss: 0.6435 - val_accuracy: 0.8042 - val_loss: 0.6561 - learning_rate: 0.0010\n",
      "Epoch 41/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7854 - loss: 0.6811 - val_accuracy: 0.8042 - val_loss: 0.6477 - learning_rate: 0.0010\n",
      "Epoch 42/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8289 - loss: 0.6158 - val_accuracy: 0.8042 - val_loss: 0.6431 - learning_rate: 0.0010\n",
      "Epoch 43/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7997 - loss: 0.6411 - val_accuracy: 0.8042 - val_loss: 0.6291 - learning_rate: 0.0010\n",
      "Epoch 44/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7820 - loss: 0.6560 - val_accuracy: 0.8042 - val_loss: 0.6178 - learning_rate: 0.0010\n",
      "Epoch 45/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8070 - loss: 0.6024 - val_accuracy: 0.8042 - val_loss: 0.6133 - learning_rate: 0.0010\n",
      "Epoch 46/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8048 - loss: 0.5948 - val_accuracy: 0.8042 - val_loss: 0.6066 - learning_rate: 0.0010\n",
      "Epoch 47/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8047 - loss: 0.6153 - val_accuracy: 0.8042 - val_loss: 0.5954 - learning_rate: 0.0010\n",
      "Epoch 48/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8100 - loss: 0.5897 - val_accuracy: 0.8042 - val_loss: 0.5876 - learning_rate: 0.0010\n",
      "Epoch 49/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8020 - loss: 0.5954 - val_accuracy: 0.8042 - val_loss: 0.5863 - learning_rate: 0.0010\n",
      "Epoch 50/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8195 - loss: 0.5634 - val_accuracy: 0.8042 - val_loss: 0.5836 - learning_rate: 0.0010\n",
      "Epoch 51/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8103 - loss: 0.5599 - val_accuracy: 0.8042 - val_loss: 0.5780 - learning_rate: 0.0010\n",
      "Epoch 52/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7973 - loss: 0.5898 - val_accuracy: 0.8042 - val_loss: 0.5751 - learning_rate: 0.0010\n",
      "Epoch 53/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8008 - loss: 0.5787 - val_accuracy: 0.8042 - val_loss: 0.5684 - learning_rate: 0.0010\n",
      "Epoch 54/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8330 - loss: 0.5068 - val_accuracy: 0.8042 - val_loss: 0.5757 - learning_rate: 0.0010\n",
      "Epoch 55/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7961 - loss: 0.5798 - val_accuracy: 0.8042 - val_loss: 0.5627 - learning_rate: 0.0010\n",
      "Epoch 56/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8016 - loss: 0.5744 - val_accuracy: 0.8042 - val_loss: 0.5588 - learning_rate: 0.0010\n",
      "Epoch 57/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8195 - loss: 0.5272 - val_accuracy: 0.8042 - val_loss: 0.5485 - learning_rate: 0.0010\n",
      "Epoch 58/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7907 - loss: 0.5718 - val_accuracy: 0.8042 - val_loss: 0.5468 - learning_rate: 0.0010\n",
      "Epoch 59/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8071 - loss: 0.5467 - val_accuracy: 0.8042 - val_loss: 0.5502 - learning_rate: 0.0010\n",
      "Epoch 60/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8149 - loss: 0.5448 - val_accuracy: 0.8042 - val_loss: 0.5544 - learning_rate: 0.0010\n",
      "Epoch 61/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7941 - loss: 0.5628 - val_accuracy: 0.8042 - val_loss: 0.5504 - learning_rate: 0.0010\n",
      "Epoch 62/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8167 - loss: 0.5360 - val_accuracy: 0.8042 - val_loss: 0.5462 - learning_rate: 0.0010\n",
      "Epoch 63/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8038 - loss: 0.5642 - val_accuracy: 0.8042 - val_loss: 0.5527 - learning_rate: 0.0010\n",
      "Epoch 64/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8003 - loss: 0.5507 - val_accuracy: 0.8042 - val_loss: 0.5405 - learning_rate: 0.0010\n",
      "Epoch 65/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8072 - loss: 0.5321 - val_accuracy: 0.8042 - val_loss: 0.5468 - learning_rate: 0.0010\n",
      "Epoch 66/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8283 - loss: 0.4991 - val_accuracy: 0.8042 - val_loss: 0.5435 - learning_rate: 0.0010\n",
      "Epoch 67/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8105 - loss: 0.5416 - val_accuracy: 0.8042 - val_loss: 0.5434 - learning_rate: 0.0010\n",
      "Epoch 68/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8153 - loss: 0.5213 - val_accuracy: 0.8042 - val_loss: 0.5479 - learning_rate: 0.0010\n",
      "Epoch 69/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8349 - loss: 0.4842 - val_accuracy: 0.8042 - val_loss: 0.5446 - learning_rate: 0.0010\n",
      "Epoch 70/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8036 - loss: 0.5508 - val_accuracy: 0.8042 - val_loss: 0.5282 - learning_rate: 0.0010\n",
      "Epoch 71/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7957 - loss: 0.5424 - val_accuracy: 0.8042 - val_loss: 0.5384 - learning_rate: 0.0010\n",
      "Epoch 72/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7927 - loss: 0.5389 - val_accuracy: 0.8042 - val_loss: 0.5369 - learning_rate: 0.0010\n",
      "Epoch 73/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8196 - loss: 0.5155 - val_accuracy: 0.8042 - val_loss: 0.5403 - learning_rate: 0.0010\n",
      "Epoch 74/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8143 - loss: 0.4991 - val_accuracy: 0.8042 - val_loss: 0.5390 - learning_rate: 0.0010\n",
      "Epoch 75/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8168 - loss: 0.5111 - val_accuracy: 0.8042 - val_loss: 0.5368 - learning_rate: 0.0010\n",
      "Epoch 76/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8264 - loss: 0.4921 - val_accuracy: 0.8042 - val_loss: 0.5283 - learning_rate: 0.0010\n",
      "Epoch 77/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8127 - loss: 0.5197 - val_accuracy: 0.8042 - val_loss: 0.5324 - learning_rate: 0.0010\n",
      "Epoch 78/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8125 - loss: 0.5297 - val_accuracy: 0.8042 - val_loss: 0.5290 - learning_rate: 0.0010\n",
      "Epoch 79/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8237 - loss: 0.4926 - val_accuracy: 0.8042 - val_loss: 0.5185 - learning_rate: 0.0010\n",
      "Epoch 80/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8039 - loss: 0.5263 - val_accuracy: 0.8042 - val_loss: 0.5235 - learning_rate: 0.0010\n",
      "Epoch 81/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8165 - loss: 0.5133 - val_accuracy: 0.8042 - val_loss: 0.5282 - learning_rate: 0.0010\n",
      "Epoch 82/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8105 - loss: 0.5154 - val_accuracy: 0.8042 - val_loss: 0.5332 - learning_rate: 0.0010\n",
      "Epoch 83/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8122 - loss: 0.5148 - val_accuracy: 0.8042 - val_loss: 0.5354 - learning_rate: 0.0010\n",
      "Epoch 84/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8029 - loss: 0.5229 - val_accuracy: 0.8042 - val_loss: 0.5464 - learning_rate: 0.0010\n",
      "Epoch 85/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8280 - loss: 0.4867 - val_accuracy: 0.8042 - val_loss: 0.5282 - learning_rate: 0.0010\n",
      "Epoch 86/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8022 - loss: 0.5200 - val_accuracy: 0.8042 - val_loss: 0.5328 - learning_rate: 0.0010\n",
      "Epoch 87/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8005 - loss: 0.5316 - val_accuracy: 0.8042 - val_loss: 0.5265 - learning_rate: 0.0010\n",
      "Epoch 88/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8106 - loss: 0.5115 - val_accuracy: 0.8042 - val_loss: 0.5276 - learning_rate: 0.0010\n",
      "Epoch 89/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7893 - loss: 0.5463 - val_accuracy: 0.8042 - val_loss: 0.5328 - learning_rate: 0.0010\n",
      "Epoch 90/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8202 - loss: 0.4973 - val_accuracy: 0.8042 - val_loss: 0.5247 - learning_rate: 5.0000e-04\n",
      "Epoch 91/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8159 - loss: 0.5018 - val_accuracy: 0.8042 - val_loss: 0.5271 - learning_rate: 5.0000e-04\n",
      "Epoch 92/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8119 - loss: 0.4938 - val_accuracy: 0.8042 - val_loss: 0.5242 - learning_rate: 5.0000e-04\n",
      "Epoch 93/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8154 - loss: 0.4959 - val_accuracy: 0.8042 - val_loss: 0.5212 - learning_rate: 5.0000e-04\n",
      "Epoch 94/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8030 - loss: 0.5202 - val_accuracy: 0.8042 - val_loss: 0.5199 - learning_rate: 5.0000e-04\n",
      "Fold 1 - Validation Loss: 0.5185, Validation Accuracy: 0.8042\n",
      "Training on Fold 2/5...\n",
      "Epoch 1/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 107ms/step - accuracy: 0.5152 - loss: 8.1883 - val_accuracy: 0.8254 - val_loss: 6.5436 - learning_rate: 0.0010\n",
      "Epoch 2/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.5532 - loss: 6.2745 - val_accuracy: 0.8254 - val_loss: 5.2564 - learning_rate: 0.0010\n",
      "Epoch 3/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5294 - loss: 5.1528 - val_accuracy: 0.8254 - val_loss: 4.4418 - learning_rate: 0.0010\n",
      "Epoch 4/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5908 - loss: 4.3799 - val_accuracy: 0.8254 - val_loss: 3.9073 - learning_rate: 0.0010\n",
      "Epoch 5/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6368 - loss: 3.8759 - val_accuracy: 0.8254 - val_loss: 3.5555 - learning_rate: 0.0010\n",
      "Epoch 6/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6433 - loss: 3.5475 - val_accuracy: 0.8254 - val_loss: 3.3029 - learning_rate: 0.0010\n",
      "Epoch 7/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6685 - loss: 3.2876 - val_accuracy: 0.8254 - val_loss: 3.0662 - learning_rate: 0.0010\n",
      "Epoch 8/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7437 - loss: 3.0405 - val_accuracy: 0.8254 - val_loss: 2.8728 - learning_rate: 0.0010\n",
      "Epoch 9/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7604 - loss: 2.8554 - val_accuracy: 0.8254 - val_loss: 2.6872 - learning_rate: 0.0010\n",
      "Epoch 10/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7523 - loss: 2.6843 - val_accuracy: 0.8254 - val_loss: 2.5232 - learning_rate: 0.0010\n",
      "Epoch 11/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7555 - loss: 2.5169 - val_accuracy: 0.8254 - val_loss: 2.3585 - learning_rate: 0.0010\n",
      "Epoch 12/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7711 - loss: 2.3954 - val_accuracy: 0.8254 - val_loss: 2.2167 - learning_rate: 0.0010\n",
      "Epoch 13/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7642 - loss: 2.2490 - val_accuracy: 0.8254 - val_loss: 2.0767 - learning_rate: 0.0010\n",
      "Epoch 14/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7754 - loss: 2.1053 - val_accuracy: 0.8254 - val_loss: 1.9571 - learning_rate: 0.0010\n",
      "Epoch 15/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7964 - loss: 1.9725 - val_accuracy: 0.8254 - val_loss: 1.8421 - learning_rate: 0.0010\n",
      "Epoch 16/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8021 - loss: 1.8320 - val_accuracy: 0.8254 - val_loss: 1.7378 - learning_rate: 0.0010\n",
      "Epoch 17/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7928 - loss: 1.7509 - val_accuracy: 0.8254 - val_loss: 1.6429 - learning_rate: 0.0010\n",
      "Epoch 18/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8004 - loss: 1.6603 - val_accuracy: 0.8254 - val_loss: 1.5508 - learning_rate: 0.0010\n",
      "Epoch 19/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7909 - loss: 1.5774 - val_accuracy: 0.8254 - val_loss: 1.4659 - learning_rate: 0.0010\n",
      "Epoch 20/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7879 - loss: 1.4782 - val_accuracy: 0.8254 - val_loss: 1.3809 - learning_rate: 0.0010\n",
      "Epoch 21/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7974 - loss: 1.4115 - val_accuracy: 0.8254 - val_loss: 1.3208 - learning_rate: 0.0010\n",
      "Epoch 22/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7746 - loss: 1.3698 - val_accuracy: 0.8254 - val_loss: 1.2569 - learning_rate: 0.0010\n",
      "Epoch 23/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8116 - loss: 1.2502 - val_accuracy: 0.8254 - val_loss: 1.1844 - learning_rate: 0.0010\n",
      "Epoch 24/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7801 - loss: 1.2405 - val_accuracy: 0.8254 - val_loss: 1.1292 - learning_rate: 0.0010\n",
      "Epoch 25/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8044 - loss: 1.1475 - val_accuracy: 0.8254 - val_loss: 1.0876 - learning_rate: 0.0010\n",
      "Epoch 26/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8040 - loss: 1.0971 - val_accuracy: 0.8254 - val_loss: 1.0453 - learning_rate: 0.0010\n",
      "Epoch 27/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7992 - loss: 1.0721 - val_accuracy: 0.8254 - val_loss: 0.9972 - learning_rate: 0.0010\n",
      "Epoch 28/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7987 - loss: 1.0162 - val_accuracy: 0.8254 - val_loss: 0.9512 - learning_rate: 0.0010\n",
      "Epoch 29/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8010 - loss: 0.9776 - val_accuracy: 0.8254 - val_loss: 0.9207 - learning_rate: 0.0010\n",
      "Epoch 30/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7891 - loss: 0.9422 - val_accuracy: 0.8254 - val_loss: 0.8891 - learning_rate: 0.0010\n",
      "Epoch 31/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7969 - loss: 0.9135 - val_accuracy: 0.8254 - val_loss: 0.8502 - learning_rate: 0.0010\n",
      "Epoch 32/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8072 - loss: 0.8742 - val_accuracy: 0.8254 - val_loss: 0.8163 - learning_rate: 0.0010\n",
      "Epoch 33/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8050 - loss: 0.8331 - val_accuracy: 0.8254 - val_loss: 0.7994 - learning_rate: 0.0010\n",
      "Epoch 34/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7857 - loss: 0.8435 - val_accuracy: 0.8254 - val_loss: 0.7773 - learning_rate: 0.0010\n",
      "Epoch 35/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8207 - loss: 0.7736 - val_accuracy: 0.8254 - val_loss: 0.7608 - learning_rate: 0.0010\n",
      "Epoch 36/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7941 - loss: 0.8026 - val_accuracy: 0.8254 - val_loss: 0.7507 - learning_rate: 0.0010\n",
      "Epoch 37/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7894 - loss: 0.7904 - val_accuracy: 0.8254 - val_loss: 0.7361 - learning_rate: 0.0010\n",
      "Epoch 38/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8127 - loss: 0.7234 - val_accuracy: 0.8254 - val_loss: 0.7106 - learning_rate: 0.0010\n",
      "Epoch 39/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7950 - loss: 0.7384 - val_accuracy: 0.8254 - val_loss: 0.6900 - learning_rate: 0.0010\n",
      "Epoch 40/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8002 - loss: 0.7154 - val_accuracy: 0.8254 - val_loss: 0.6754 - learning_rate: 0.0010\n",
      "Epoch 41/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8028 - loss: 0.6992 - val_accuracy: 0.8254 - val_loss: 0.6581 - learning_rate: 0.0010\n",
      "Epoch 42/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7721 - loss: 0.7259 - val_accuracy: 0.8254 - val_loss: 0.6502 - learning_rate: 0.0010\n",
      "Epoch 43/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8009 - loss: 0.6836 - val_accuracy: 0.8254 - val_loss: 0.6470 - learning_rate: 0.0010\n",
      "Epoch 44/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7836 - loss: 0.6884 - val_accuracy: 0.8254 - val_loss: 0.6377 - learning_rate: 0.0010\n",
      "Epoch 45/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7898 - loss: 0.6692 - val_accuracy: 0.8254 - val_loss: 0.6274 - learning_rate: 0.0010\n",
      "Epoch 46/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8170 - loss: 0.6419 - val_accuracy: 0.8254 - val_loss: 0.6156 - learning_rate: 0.0010\n",
      "Epoch 47/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8147 - loss: 0.6377 - val_accuracy: 0.8254 - val_loss: 0.6013 - learning_rate: 0.0010\n",
      "Epoch 48/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8088 - loss: 0.6254 - val_accuracy: 0.8254 - val_loss: 0.5942 - learning_rate: 0.0010\n",
      "Epoch 49/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8024 - loss: 0.6421 - val_accuracy: 0.8254 - val_loss: 0.5920 - learning_rate: 0.0010\n",
      "Epoch 50/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8215 - loss: 0.5967 - val_accuracy: 0.8254 - val_loss: 0.5754 - learning_rate: 0.0010\n",
      "Epoch 51/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7950 - loss: 0.6305 - val_accuracy: 0.8254 - val_loss: 0.5722 - learning_rate: 0.0010\n",
      "Epoch 52/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8032 - loss: 0.6104 - val_accuracy: 0.8254 - val_loss: 0.5650 - learning_rate: 0.0010\n",
      "Epoch 53/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8016 - loss: 0.5956 - val_accuracy: 0.8254 - val_loss: 0.5594 - learning_rate: 0.0010\n",
      "Epoch 54/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8112 - loss: 0.5738 - val_accuracy: 0.8254 - val_loss: 0.5531 - learning_rate: 0.0010\n",
      "Epoch 55/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8061 - loss: 0.5792 - val_accuracy: 0.8254 - val_loss: 0.5491 - learning_rate: 0.0010\n",
      "Epoch 56/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8160 - loss: 0.5715 - val_accuracy: 0.8254 - val_loss: 0.5439 - learning_rate: 0.0010\n",
      "Epoch 57/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8092 - loss: 0.5805 - val_accuracy: 0.8254 - val_loss: 0.5419 - learning_rate: 0.0010\n",
      "Epoch 58/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8101 - loss: 0.5568 - val_accuracy: 0.8254 - val_loss: 0.5396 - learning_rate: 0.0010\n",
      "Epoch 59/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7800 - loss: 0.6043 - val_accuracy: 0.8254 - val_loss: 0.5386 - learning_rate: 0.0010\n",
      "Epoch 60/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7978 - loss: 0.5820 - val_accuracy: 0.8254 - val_loss: 0.5368 - learning_rate: 0.0010\n",
      "Epoch 61/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8001 - loss: 0.5663 - val_accuracy: 0.8254 - val_loss: 0.5270 - learning_rate: 0.0010\n",
      "Epoch 62/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7825 - loss: 0.5952 - val_accuracy: 0.8254 - val_loss: 0.5324 - learning_rate: 0.0010\n",
      "Epoch 63/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8227 - loss: 0.5337 - val_accuracy: 0.8254 - val_loss: 0.5222 - learning_rate: 0.0010\n",
      "Epoch 64/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8132 - loss: 0.5388 - val_accuracy: 0.8254 - val_loss: 0.5197 - learning_rate: 0.0010\n",
      "Epoch 65/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8139 - loss: 0.5341 - val_accuracy: 0.8254 - val_loss: 0.5123 - learning_rate: 0.0010\n",
      "Epoch 66/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8021 - loss: 0.5509 - val_accuracy: 0.8254 - val_loss: 0.5101 - learning_rate: 0.0010\n",
      "Epoch 67/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8172 - loss: 0.5245 - val_accuracy: 0.8254 - val_loss: 0.5071 - learning_rate: 0.0010\n",
      "Epoch 68/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8090 - loss: 0.5475 - val_accuracy: 0.8254 - val_loss: 0.5062 - learning_rate: 0.0010\n",
      "Epoch 69/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8120 - loss: 0.5374 - val_accuracy: 0.8254 - val_loss: 0.5020 - learning_rate: 0.0010\n",
      "Epoch 70/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7847 - loss: 0.5609 - val_accuracy: 0.8254 - val_loss: 0.5020 - learning_rate: 0.0010\n",
      "Epoch 71/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8041 - loss: 0.5363 - val_accuracy: 0.8254 - val_loss: 0.4990 - learning_rate: 0.0010\n",
      "Epoch 72/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8164 - loss: 0.5122 - val_accuracy: 0.8254 - val_loss: 0.4989 - learning_rate: 0.0010\n",
      "Epoch 73/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7586 - loss: 0.6116 - val_accuracy: 0.8254 - val_loss: 0.5022 - learning_rate: 0.0010\n",
      "Epoch 74/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7878 - loss: 0.5622 - val_accuracy: 0.8254 - val_loss: 0.5026 - learning_rate: 0.0010\n",
      "Epoch 75/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8148 - loss: 0.5224 - val_accuracy: 0.8254 - val_loss: 0.4954 - learning_rate: 0.0010\n",
      "Epoch 76/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8173 - loss: 0.5069 - val_accuracy: 0.8254 - val_loss: 0.4933 - learning_rate: 0.0010\n",
      "Epoch 77/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7978 - loss: 0.5393 - val_accuracy: 0.8254 - val_loss: 0.4939 - learning_rate: 0.0010\n",
      "Epoch 78/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8230 - loss: 0.4952 - val_accuracy: 0.8254 - val_loss: 0.4918 - learning_rate: 0.0010\n",
      "Epoch 79/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8016 - loss: 0.5308 - val_accuracy: 0.8254 - val_loss: 0.4952 - learning_rate: 0.0010\n",
      "Epoch 80/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7911 - loss: 0.5499 - val_accuracy: 0.8254 - val_loss: 0.4917 - learning_rate: 0.0010\n",
      "Epoch 81/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7922 - loss: 0.5409 - val_accuracy: 0.8254 - val_loss: 0.4912 - learning_rate: 0.0010\n",
      "Epoch 82/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8077 - loss: 0.5261 - val_accuracy: 0.8254 - val_loss: 0.4918 - learning_rate: 0.0010\n",
      "Epoch 83/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7984 - loss: 0.5294 - val_accuracy: 0.8254 - val_loss: 0.4879 - learning_rate: 0.0010\n",
      "Epoch 84/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8109 - loss: 0.5039 - val_accuracy: 0.8254 - val_loss: 0.4857 - learning_rate: 0.0010\n",
      "Epoch 85/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8069 - loss: 0.5136 - val_accuracy: 0.8254 - val_loss: 0.4853 - learning_rate: 0.0010\n",
      "Epoch 86/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7789 - loss: 0.5649 - val_accuracy: 0.8254 - val_loss: 0.4846 - learning_rate: 0.0010\n",
      "Epoch 87/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8135 - loss: 0.5039 - val_accuracy: 0.8254 - val_loss: 0.4910 - learning_rate: 0.0010\n",
      "Epoch 88/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8005 - loss: 0.5299 - val_accuracy: 0.8254 - val_loss: 0.4856 - learning_rate: 0.0010\n",
      "Epoch 89/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8404 - loss: 0.4650 - val_accuracy: 0.8254 - val_loss: 0.4871 - learning_rate: 0.0010\n",
      "Epoch 90/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8218 - loss: 0.5024 - val_accuracy: 0.8254 - val_loss: 0.4887 - learning_rate: 0.0010\n",
      "Epoch 91/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7806 - loss: 0.5501 - val_accuracy: 0.8254 - val_loss: 0.4882 - learning_rate: 0.0010\n",
      "Epoch 92/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8010 - loss: 0.5249 - val_accuracy: 0.8254 - val_loss: 0.4803 - learning_rate: 0.0010\n",
      "Epoch 93/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8261 - loss: 0.4886 - val_accuracy: 0.8254 - val_loss: 0.4800 - learning_rate: 0.0010\n",
      "Epoch 94/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8087 - loss: 0.5053 - val_accuracy: 0.8254 - val_loss: 0.4803 - learning_rate: 0.0010\n",
      "Epoch 95/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7973 - loss: 0.5222 - val_accuracy: 0.8254 - val_loss: 0.4838 - learning_rate: 0.0010\n",
      "Epoch 96/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7881 - loss: 0.5366 - val_accuracy: 0.8254 - val_loss: 0.4909 - learning_rate: 0.0010\n",
      "Epoch 97/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8040 - loss: 0.5184 - val_accuracy: 0.8254 - val_loss: 0.4900 - learning_rate: 0.0010\n",
      "Epoch 98/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8195 - loss: 0.4913 - val_accuracy: 0.8254 - val_loss: 0.4852 - learning_rate: 0.0010\n",
      "Epoch 99/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7977 - loss: 0.5335 - val_accuracy: 0.8254 - val_loss: 0.4904 - learning_rate: 0.0010\n",
      "Epoch 100/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8241 - loss: 0.4880 - val_accuracy: 0.8254 - val_loss: 0.4863 - learning_rate: 0.0010\n",
      "Epoch 101/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7908 - loss: 0.5349 - val_accuracy: 0.8254 - val_loss: 0.4888 - learning_rate: 0.0010\n",
      "Epoch 102/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8164 - loss: 0.4972 - val_accuracy: 0.8254 - val_loss: 0.4880 - learning_rate: 0.0010\n",
      "Epoch 103/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7770 - loss: 0.5576 - val_accuracy: 0.8254 - val_loss: 0.4966 - learning_rate: 0.0010\n",
      "Epoch 104/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8160 - loss: 0.4976 - val_accuracy: 0.8254 - val_loss: 0.4865 - learning_rate: 5.0000e-04\n",
      "Epoch 105/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7893 - loss: 0.5284 - val_accuracy: 0.8254 - val_loss: 0.4820 - learning_rate: 5.0000e-04\n",
      "Epoch 106/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8170 - loss: 0.4923 - val_accuracy: 0.8254 - val_loss: 0.4806 - learning_rate: 5.0000e-04\n",
      "Epoch 107/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8140 - loss: 0.5013 - val_accuracy: 0.8254 - val_loss: 0.4790 - learning_rate: 5.0000e-04\n",
      "Epoch 108/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8036 - loss: 0.5107 - val_accuracy: 0.8254 - val_loss: 0.4788 - learning_rate: 5.0000e-04\n",
      "Epoch 109/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7947 - loss: 0.5217 - val_accuracy: 0.8254 - val_loss: 0.4811 - learning_rate: 5.0000e-04\n",
      "Epoch 110/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8147 - loss: 0.5021 - val_accuracy: 0.8254 - val_loss: 0.4804 - learning_rate: 5.0000e-04\n",
      "Epoch 111/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8027 - loss: 0.5155 - val_accuracy: 0.8254 - val_loss: 0.4785 - learning_rate: 5.0000e-04\n",
      "Epoch 112/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8084 - loss: 0.5134 - val_accuracy: 0.8254 - val_loss: 0.4778 - learning_rate: 5.0000e-04\n",
      "Epoch 113/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8011 - loss: 0.5159 - val_accuracy: 0.8254 - val_loss: 0.4766 - learning_rate: 5.0000e-04\n",
      "Epoch 114/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8130 - loss: 0.4937 - val_accuracy: 0.8254 - val_loss: 0.4772 - learning_rate: 5.0000e-04\n",
      "Epoch 115/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8172 - loss: 0.4931 - val_accuracy: 0.8254 - val_loss: 0.4788 - learning_rate: 5.0000e-04\n",
      "Epoch 116/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7862 - loss: 0.5327 - val_accuracy: 0.8254 - val_loss: 0.4777 - learning_rate: 5.0000e-04\n",
      "Epoch 117/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8012 - loss: 0.5148 - val_accuracy: 0.8254 - val_loss: 0.4789 - learning_rate: 5.0000e-04\n",
      "Epoch 118/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7998 - loss: 0.5132 - val_accuracy: 0.8254 - val_loss: 0.4782 - learning_rate: 5.0000e-04\n",
      "Epoch 119/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8010 - loss: 0.5147 - val_accuracy: 0.8254 - val_loss: 0.4788 - learning_rate: 5.0000e-04\n",
      "Epoch 120/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7890 - loss: 0.5274 - val_accuracy: 0.8254 - val_loss: 0.4794 - learning_rate: 5.0000e-04\n",
      "Epoch 121/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7924 - loss: 0.5169 - val_accuracy: 0.8254 - val_loss: 0.4753 - learning_rate: 5.0000e-04\n",
      "Epoch 122/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8050 - loss: 0.5078 - val_accuracy: 0.8254 - val_loss: 0.4761 - learning_rate: 5.0000e-04\n",
      "Epoch 123/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8210 - loss: 0.4891 - val_accuracy: 0.8254 - val_loss: 0.4780 - learning_rate: 5.0000e-04\n",
      "Epoch 124/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8125 - loss: 0.5012 - val_accuracy: 0.8254 - val_loss: 0.4752 - learning_rate: 5.0000e-04\n",
      "Epoch 125/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8291 - loss: 0.4777 - val_accuracy: 0.8254 - val_loss: 0.4757 - learning_rate: 5.0000e-04\n",
      "Epoch 126/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8125 - loss: 0.4924 - val_accuracy: 0.8254 - val_loss: 0.4782 - learning_rate: 5.0000e-04\n",
      "Epoch 127/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8155 - loss: 0.4889 - val_accuracy: 0.8254 - val_loss: 0.4816 - learning_rate: 5.0000e-04\n",
      "Epoch 128/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8132 - loss: 0.4976 - val_accuracy: 0.8254 - val_loss: 0.4761 - learning_rate: 5.0000e-04\n",
      "Epoch 129/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8008 - loss: 0.5089 - val_accuracy: 0.8254 - val_loss: 0.4823 - learning_rate: 5.0000e-04\n",
      "Epoch 130/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8013 - loss: 0.5124 - val_accuracy: 0.8254 - val_loss: 0.4799 - learning_rate: 5.0000e-04\n",
      "Epoch 131/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7969 - loss: 0.5138 - val_accuracy: 0.8254 - val_loss: 0.4781 - learning_rate: 5.0000e-04\n",
      "Epoch 132/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8098 - loss: 0.5063 - val_accuracy: 0.8254 - val_loss: 0.4751 - learning_rate: 2.5000e-04\n",
      "Epoch 133/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8016 - loss: 0.5065 - val_accuracy: 0.8254 - val_loss: 0.4736 - learning_rate: 2.5000e-04\n",
      "Epoch 134/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8289 - loss: 0.4683 - val_accuracy: 0.8254 - val_loss: 0.4742 - learning_rate: 2.5000e-04\n",
      "Epoch 135/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8025 - loss: 0.5145 - val_accuracy: 0.8254 - val_loss: 0.4739 - learning_rate: 2.5000e-04\n",
      "Epoch 136/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8195 - loss: 0.4818 - val_accuracy: 0.8254 - val_loss: 0.4728 - learning_rate: 2.5000e-04\n",
      "Epoch 137/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8196 - loss: 0.4810 - val_accuracy: 0.8254 - val_loss: 0.4728 - learning_rate: 2.5000e-04\n",
      "Epoch 138/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8251 - loss: 0.4751 - val_accuracy: 0.8254 - val_loss: 0.4726 - learning_rate: 2.5000e-04\n",
      "Epoch 139/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8025 - loss: 0.5006 - val_accuracy: 0.8254 - val_loss: 0.4719 - learning_rate: 2.5000e-04\n",
      "Epoch 140/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7922 - loss: 0.5230 - val_accuracy: 0.8254 - val_loss: 0.4720 - learning_rate: 2.5000e-04\n",
      "Epoch 141/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7908 - loss: 0.5264 - val_accuracy: 0.8254 - val_loss: 0.4714 - learning_rate: 2.5000e-04\n",
      "Epoch 142/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7946 - loss: 0.5201 - val_accuracy: 0.8254 - val_loss: 0.4715 - learning_rate: 2.5000e-04\n",
      "Epoch 143/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8072 - loss: 0.5038 - val_accuracy: 0.8254 - val_loss: 0.4721 - learning_rate: 2.5000e-04\n",
      "Epoch 144/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8133 - loss: 0.4796 - val_accuracy: 0.8254 - val_loss: 0.4716 - learning_rate: 2.5000e-04\n",
      "Epoch 145/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8071 - loss: 0.5058 - val_accuracy: 0.8254 - val_loss: 0.4723 - learning_rate: 2.5000e-04\n",
      "Epoch 146/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8004 - loss: 0.5081 - val_accuracy: 0.8254 - val_loss: 0.4720 - learning_rate: 2.5000e-04\n",
      "Epoch 147/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8023 - loss: 0.5046 - val_accuracy: 0.8254 - val_loss: 0.4712 - learning_rate: 2.5000e-04\n",
      "Epoch 148/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8214 - loss: 0.4799 - val_accuracy: 0.8254 - val_loss: 0.4703 - learning_rate: 2.5000e-04\n",
      "Epoch 149/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8230 - loss: 0.4682 - val_accuracy: 0.8254 - val_loss: 0.4703 - learning_rate: 2.5000e-04\n",
      "Epoch 150/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8157 - loss: 0.4817 - val_accuracy: 0.8254 - val_loss: 0.4703 - learning_rate: 2.5000e-04\n",
      "Fold 2 - Validation Loss: 0.4703, Validation Accuracy: 0.8254\n",
      "Training on Fold 3/5...\n",
      "Epoch 1/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 107ms/step - accuracy: 0.5099 - loss: 8.1743 - val_accuracy: 0.7819 - val_loss: 6.5407 - learning_rate: 0.0010\n",
      "Epoch 2/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5616 - loss: 6.3288 - val_accuracy: 0.7819 - val_loss: 5.2670 - learning_rate: 0.0010\n",
      "Epoch 3/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5774 - loss: 5.1775 - val_accuracy: 0.7819 - val_loss: 4.4850 - learning_rate: 0.0010\n",
      "Epoch 4/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6632 - loss: 4.4003 - val_accuracy: 0.7819 - val_loss: 3.9701 - learning_rate: 0.0010\n",
      "Epoch 5/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6892 - loss: 3.9294 - val_accuracy: 0.7819 - val_loss: 3.6200 - learning_rate: 0.0010\n",
      "Epoch 6/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6727 - loss: 3.6560 - val_accuracy: 0.7819 - val_loss: 3.3567 - learning_rate: 0.0010\n",
      "Epoch 7/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7105 - loss: 3.3528 - val_accuracy: 0.7819 - val_loss: 3.1329 - learning_rate: 0.0010\n",
      "Epoch 8/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7372 - loss: 3.1343 - val_accuracy: 0.7819 - val_loss: 2.9368 - learning_rate: 0.0010\n",
      "Epoch 9/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7535 - loss: 2.8990 - val_accuracy: 0.7819 - val_loss: 2.7632 - learning_rate: 0.0010\n",
      "Epoch 10/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7507 - loss: 2.7600 - val_accuracy: 0.7819 - val_loss: 2.6093 - learning_rate: 0.0010\n",
      "Epoch 11/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7743 - loss: 2.6058 - val_accuracy: 0.7819 - val_loss: 2.4552 - learning_rate: 0.0010\n",
      "Epoch 12/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7539 - loss: 2.4405 - val_accuracy: 0.7819 - val_loss: 2.3152 - learning_rate: 0.0010\n",
      "Epoch 13/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7915 - loss: 2.2858 - val_accuracy: 0.7819 - val_loss: 2.1833 - learning_rate: 0.0010\n",
      "Epoch 14/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7990 - loss: 2.1383 - val_accuracy: 0.7819 - val_loss: 2.0630 - learning_rate: 0.0010\n",
      "Epoch 15/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7951 - loss: 2.0571 - val_accuracy: 0.7819 - val_loss: 1.9518 - learning_rate: 0.0010\n",
      "Epoch 16/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7828 - loss: 1.9349 - val_accuracy: 0.7819 - val_loss: 1.8481 - learning_rate: 0.0010\n",
      "Epoch 17/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7882 - loss: 1.8518 - val_accuracy: 0.7819 - val_loss: 1.7516 - learning_rate: 0.0010\n",
      "Epoch 18/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8045 - loss: 1.7032 - val_accuracy: 0.7819 - val_loss: 1.6627 - learning_rate: 0.0010\n",
      "Epoch 19/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8106 - loss: 1.6305 - val_accuracy: 0.7819 - val_loss: 1.5783 - learning_rate: 0.0010\n",
      "Epoch 20/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7975 - loss: 1.5522 - val_accuracy: 0.7819 - val_loss: 1.5002 - learning_rate: 0.0010\n",
      "Epoch 21/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8145 - loss: 1.4492 - val_accuracy: 0.7819 - val_loss: 1.4281 - learning_rate: 0.0010\n",
      "Epoch 22/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8228 - loss: 1.3859 - val_accuracy: 0.7819 - val_loss: 1.3624 - learning_rate: 0.0010\n",
      "Epoch 23/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7942 - loss: 1.3338 - val_accuracy: 0.7819 - val_loss: 1.3000 - learning_rate: 0.0010\n",
      "Epoch 24/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8106 - loss: 1.2679 - val_accuracy: 0.7819 - val_loss: 1.2420 - learning_rate: 0.0010\n",
      "Epoch 25/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7897 - loss: 1.2265 - val_accuracy: 0.7819 - val_loss: 1.1874 - learning_rate: 0.0010\n",
      "Epoch 26/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7904 - loss: 1.1868 - val_accuracy: 0.7819 - val_loss: 1.1383 - learning_rate: 0.0010\n",
      "Epoch 27/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8038 - loss: 1.1171 - val_accuracy: 0.7819 - val_loss: 1.0922 - learning_rate: 0.0010\n",
      "Epoch 28/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8062 - loss: 1.0796 - val_accuracy: 0.7819 - val_loss: 1.0501 - learning_rate: 0.0010\n",
      "Epoch 29/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8159 - loss: 0.9798 - val_accuracy: 0.7819 - val_loss: 1.0114 - learning_rate: 0.0010\n",
      "Epoch 30/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7968 - loss: 1.0213 - val_accuracy: 0.7819 - val_loss: 0.9749 - learning_rate: 0.0010\n",
      "Epoch 31/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8163 - loss: 0.9283 - val_accuracy: 0.7819 - val_loss: 0.9410 - learning_rate: 0.0010\n",
      "Epoch 32/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8179 - loss: 0.8880 - val_accuracy: 0.7819 - val_loss: 0.9136 - learning_rate: 0.0010\n",
      "Epoch 33/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8258 - loss: 0.8699 - val_accuracy: 0.7819 - val_loss: 0.8855 - learning_rate: 0.0010\n",
      "Epoch 34/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8048 - loss: 0.8604 - val_accuracy: 0.7819 - val_loss: 0.8603 - learning_rate: 0.0010\n",
      "Epoch 35/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8132 - loss: 0.8389 - val_accuracy: 0.7819 - val_loss: 0.8335 - learning_rate: 0.0010\n",
      "Epoch 36/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8218 - loss: 0.7951 - val_accuracy: 0.7819 - val_loss: 0.8129 - learning_rate: 0.0010\n",
      "Epoch 37/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8099 - loss: 0.7829 - val_accuracy: 0.7819 - val_loss: 0.7926 - learning_rate: 0.0010\n",
      "Epoch 38/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8121 - loss: 0.7693 - val_accuracy: 0.7819 - val_loss: 0.7726 - learning_rate: 0.0010\n",
      "Epoch 39/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7978 - loss: 0.7554 - val_accuracy: 0.7819 - val_loss: 0.7598 - learning_rate: 0.0010\n",
      "Epoch 40/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8275 - loss: 0.6960 - val_accuracy: 0.7819 - val_loss: 0.7425 - learning_rate: 0.0010\n",
      "Epoch 41/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8059 - loss: 0.7259 - val_accuracy: 0.7819 - val_loss: 0.7286 - learning_rate: 0.0010\n",
      "Epoch 42/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8085 - loss: 0.6932 - val_accuracy: 0.7819 - val_loss: 0.7143 - learning_rate: 0.0010\n",
      "Epoch 43/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8115 - loss: 0.6910 - val_accuracy: 0.7819 - val_loss: 0.7042 - learning_rate: 0.0010\n",
      "Epoch 44/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8274 - loss: 0.6515 - val_accuracy: 0.7819 - val_loss: 0.6896 - learning_rate: 0.0010\n",
      "Epoch 45/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8130 - loss: 0.6631 - val_accuracy: 0.7819 - val_loss: 0.6785 - learning_rate: 0.0010\n",
      "Epoch 46/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8244 - loss: 0.6334 - val_accuracy: 0.7819 - val_loss: 0.6668 - learning_rate: 0.0010\n",
      "Epoch 47/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7920 - loss: 0.6567 - val_accuracy: 0.7819 - val_loss: 0.6557 - learning_rate: 0.0010\n",
      "Epoch 48/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8066 - loss: 0.6190 - val_accuracy: 0.7819 - val_loss: 0.6514 - learning_rate: 0.0010\n",
      "Epoch 49/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8139 - loss: 0.6191 - val_accuracy: 0.7819 - val_loss: 0.6532 - learning_rate: 0.0010\n",
      "Epoch 50/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8214 - loss: 0.5977 - val_accuracy: 0.7819 - val_loss: 0.6386 - learning_rate: 0.0010\n",
      "Epoch 51/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8146 - loss: 0.5927 - val_accuracy: 0.7819 - val_loss: 0.6331 - learning_rate: 0.0010\n",
      "Epoch 52/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8068 - loss: 0.6009 - val_accuracy: 0.7819 - val_loss: 0.6265 - learning_rate: 0.0010\n",
      "Epoch 53/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8240 - loss: 0.5793 - val_accuracy: 0.7819 - val_loss: 0.6245 - learning_rate: 0.0010\n",
      "Epoch 54/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8116 - loss: 0.5852 - val_accuracy: 0.7819 - val_loss: 0.6178 - learning_rate: 0.0010\n",
      "Epoch 55/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8057 - loss: 0.5744 - val_accuracy: 0.7819 - val_loss: 0.6095 - learning_rate: 0.0010\n",
      "Epoch 56/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8157 - loss: 0.5741 - val_accuracy: 0.7819 - val_loss: 0.6031 - learning_rate: 0.0010\n",
      "Epoch 57/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8221 - loss: 0.5626 - val_accuracy: 0.7819 - val_loss: 0.5967 - learning_rate: 0.0010\n",
      "Epoch 58/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8244 - loss: 0.5367 - val_accuracy: 0.7819 - val_loss: 0.5967 - learning_rate: 0.0010\n",
      "Epoch 59/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8278 - loss: 0.5462 - val_accuracy: 0.7819 - val_loss: 0.5909 - learning_rate: 0.0010\n",
      "Epoch 60/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8313 - loss: 0.5308 - val_accuracy: 0.7819 - val_loss: 0.5860 - learning_rate: 0.0010\n",
      "Epoch 61/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8070 - loss: 0.5756 - val_accuracy: 0.7819 - val_loss: 0.5859 - learning_rate: 0.0010\n",
      "Epoch 62/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8322 - loss: 0.5223 - val_accuracy: 0.7819 - val_loss: 0.5793 - learning_rate: 0.0010\n",
      "Epoch 63/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8116 - loss: 0.5393 - val_accuracy: 0.7819 - val_loss: 0.5786 - learning_rate: 0.0010\n",
      "Epoch 64/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8195 - loss: 0.5308 - val_accuracy: 0.7819 - val_loss: 0.5785 - learning_rate: 0.0010\n",
      "Epoch 65/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8189 - loss: 0.5351 - val_accuracy: 0.7819 - val_loss: 0.5751 - learning_rate: 0.0010\n",
      "Epoch 66/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8161 - loss: 0.5461 - val_accuracy: 0.7819 - val_loss: 0.5759 - learning_rate: 0.0010\n",
      "Epoch 67/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8103 - loss: 0.5408 - val_accuracy: 0.7819 - val_loss: 0.5739 - learning_rate: 0.0010\n",
      "Epoch 68/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8055 - loss: 0.5430 - val_accuracy: 0.7819 - val_loss: 0.5758 - learning_rate: 0.0010\n",
      "Epoch 69/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8251 - loss: 0.5185 - val_accuracy: 0.7819 - val_loss: 0.5758 - learning_rate: 0.0010\n",
      "Epoch 70/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7924 - loss: 0.5645 - val_accuracy: 0.7819 - val_loss: 0.5703 - learning_rate: 0.0010\n",
      "Epoch 71/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8277 - loss: 0.5019 - val_accuracy: 0.7819 - val_loss: 0.5617 - learning_rate: 0.0010\n",
      "Epoch 72/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8171 - loss: 0.5322 - val_accuracy: 0.7819 - val_loss: 0.5605 - learning_rate: 0.0010\n",
      "Epoch 73/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7895 - loss: 0.5605 - val_accuracy: 0.7819 - val_loss: 0.5570 - learning_rate: 0.0010\n",
      "Epoch 74/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8197 - loss: 0.5093 - val_accuracy: 0.7819 - val_loss: 0.5580 - learning_rate: 0.0010\n",
      "Epoch 75/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8112 - loss: 0.5254 - val_accuracy: 0.7819 - val_loss: 0.5613 - learning_rate: 0.0010\n",
      "Epoch 76/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8114 - loss: 0.5179 - val_accuracy: 0.7819 - val_loss: 0.5632 - learning_rate: 0.0010\n",
      "Epoch 77/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8119 - loss: 0.5188 - val_accuracy: 0.7819 - val_loss: 0.5606 - learning_rate: 0.0010\n",
      "Epoch 78/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8207 - loss: 0.5165 - val_accuracy: 0.7819 - val_loss: 0.5560 - learning_rate: 0.0010\n",
      "Epoch 79/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7839 - loss: 0.5624 - val_accuracy: 0.7819 - val_loss: 0.5538 - learning_rate: 0.0010\n",
      "Epoch 80/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8448 - loss: 0.4747 - val_accuracy: 0.7819 - val_loss: 0.5568 - learning_rate: 0.0010\n",
      "Epoch 81/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7913 - loss: 0.5450 - val_accuracy: 0.7819 - val_loss: 0.5517 - learning_rate: 0.0010\n",
      "Epoch 82/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8312 - loss: 0.4888 - val_accuracy: 0.7819 - val_loss: 0.5489 - learning_rate: 0.0010\n",
      "Epoch 83/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8091 - loss: 0.5191 - val_accuracy: 0.7819 - val_loss: 0.5475 - learning_rate: 0.0010\n",
      "Epoch 84/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8000 - loss: 0.5256 - val_accuracy: 0.7819 - val_loss: 0.5462 - learning_rate: 0.0010\n",
      "Epoch 85/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8134 - loss: 0.5096 - val_accuracy: 0.7819 - val_loss: 0.5453 - learning_rate: 0.0010\n",
      "Epoch 86/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8243 - loss: 0.4974 - val_accuracy: 0.7819 - val_loss: 0.5452 - learning_rate: 0.0010\n",
      "Epoch 87/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8215 - loss: 0.4931 - val_accuracy: 0.7819 - val_loss: 0.5502 - learning_rate: 0.0010\n",
      "Epoch 88/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7967 - loss: 0.5406 - val_accuracy: 0.7819 - val_loss: 0.5506 - learning_rate: 0.0010\n",
      "Epoch 89/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8158 - loss: 0.5086 - val_accuracy: 0.7819 - val_loss: 0.5504 - learning_rate: 0.0010\n",
      "Epoch 90/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8187 - loss: 0.5109 - val_accuracy: 0.7819 - val_loss: 0.5505 - learning_rate: 0.0010\n",
      "Epoch 91/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8222 - loss: 0.4997 - val_accuracy: 0.7819 - val_loss: 0.5516 - learning_rate: 0.0010\n",
      "Epoch 92/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8169 - loss: 0.5081 - val_accuracy: 0.7819 - val_loss: 0.5467 - learning_rate: 0.0010\n",
      "Epoch 93/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8254 - loss: 0.4942 - val_accuracy: 0.7819 - val_loss: 0.5553 - learning_rate: 0.0010\n",
      "Epoch 94/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8245 - loss: 0.4954 - val_accuracy: 0.7819 - val_loss: 0.5535 - learning_rate: 0.0010\n",
      "Epoch 95/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7941 - loss: 0.5492 - val_accuracy: 0.7819 - val_loss: 0.5535 - learning_rate: 0.0010\n",
      "Epoch 96/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8088 - loss: 0.5247 - val_accuracy: 0.7819 - val_loss: 0.5484 - learning_rate: 5.0000e-04\n",
      "Epoch 97/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8195 - loss: 0.4999 - val_accuracy: 0.7819 - val_loss: 0.5479 - learning_rate: 5.0000e-04\n",
      "Epoch 98/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7953 - loss: 0.5240 - val_accuracy: 0.7819 - val_loss: 0.5463 - learning_rate: 5.0000e-04\n",
      "Epoch 99/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8156 - loss: 0.5047 - val_accuracy: 0.7819 - val_loss: 0.5470 - learning_rate: 5.0000e-04\n",
      "Epoch 100/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8289 - loss: 0.4718 - val_accuracy: 0.7819 - val_loss: 0.5475 - learning_rate: 5.0000e-04\n",
      "Epoch 101/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8096 - loss: 0.5198 - val_accuracy: 0.7819 - val_loss: 0.5488 - learning_rate: 5.0000e-04\n",
      "Fold 3 - Validation Loss: 0.5452, Validation Accuracy: 0.7819\n",
      "Training on Fold 4/5...\n",
      "Epoch 1/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 107ms/step - accuracy: 0.4876 - loss: 8.3457 - val_accuracy: 0.8457 - val_loss: 6.6872 - learning_rate: 0.0010\n",
      "Epoch 2/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5434 - loss: 6.5213 - val_accuracy: 0.8457 - val_loss: 5.4619 - learning_rate: 0.0010\n",
      "Epoch 3/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6135 - loss: 5.3960 - val_accuracy: 0.8457 - val_loss: 4.6884 - learning_rate: 0.0010\n",
      "Epoch 4/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6026 - loss: 4.6915 - val_accuracy: 0.8457 - val_loss: 4.1569 - learning_rate: 0.0010\n",
      "Epoch 5/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6737 - loss: 4.1749 - val_accuracy: 0.8457 - val_loss: 3.7902 - learning_rate: 0.0010\n",
      "Epoch 6/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6625 - loss: 3.8375 - val_accuracy: 0.8457 - val_loss: 3.5177 - learning_rate: 0.0010\n",
      "Epoch 7/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6970 - loss: 3.5765 - val_accuracy: 0.8457 - val_loss: 3.2869 - learning_rate: 0.0010\n",
      "Epoch 8/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6713 - loss: 3.4129 - val_accuracy: 0.8457 - val_loss: 3.0908 - learning_rate: 0.0010\n",
      "Epoch 9/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7662 - loss: 3.1280 - val_accuracy: 0.8457 - val_loss: 2.9168 - learning_rate: 0.0010\n",
      "Epoch 10/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7297 - loss: 3.0025 - val_accuracy: 0.8457 - val_loss: 2.7477 - learning_rate: 0.0010\n",
      "Epoch 11/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7399 - loss: 2.8448 - val_accuracy: 0.8457 - val_loss: 2.5919 - learning_rate: 0.0010\n",
      "Epoch 12/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7370 - loss: 2.6867 - val_accuracy: 0.8457 - val_loss: 2.4573 - learning_rate: 0.0010\n",
      "Epoch 13/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7569 - loss: 2.5210 - val_accuracy: 0.8457 - val_loss: 2.3157 - learning_rate: 0.0010\n",
      "Epoch 14/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7915 - loss: 2.3604 - val_accuracy: 0.8457 - val_loss: 2.1845 - learning_rate: 0.0010\n",
      "Epoch 15/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7267 - loss: 2.3360 - val_accuracy: 0.8457 - val_loss: 2.0711 - learning_rate: 0.0010\n",
      "Epoch 16/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7888 - loss: 2.1681 - val_accuracy: 0.8457 - val_loss: 1.9535 - learning_rate: 0.0010\n",
      "Epoch 17/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7995 - loss: 2.0227 - val_accuracy: 0.8457 - val_loss: 1.8520 - learning_rate: 0.0010\n",
      "Epoch 18/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7949 - loss: 1.9286 - val_accuracy: 0.8457 - val_loss: 1.7467 - learning_rate: 0.0010\n",
      "Epoch 19/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7948 - loss: 1.8151 - val_accuracy: 0.8457 - val_loss: 1.6583 - learning_rate: 0.0010\n",
      "Epoch 20/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7871 - loss: 1.7279 - val_accuracy: 0.8457 - val_loss: 1.5768 - learning_rate: 0.0010\n",
      "Epoch 21/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7753 - loss: 1.6652 - val_accuracy: 0.8457 - val_loss: 1.4923 - learning_rate: 0.0010\n",
      "Epoch 22/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8072 - loss: 1.5515 - val_accuracy: 0.8457 - val_loss: 1.4127 - learning_rate: 0.0010\n",
      "Epoch 23/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7895 - loss: 1.4824 - val_accuracy: 0.8457 - val_loss: 1.3490 - learning_rate: 0.0010\n",
      "Epoch 24/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7999 - loss: 1.4214 - val_accuracy: 0.8457 - val_loss: 1.2821 - learning_rate: 0.0010\n",
      "Epoch 25/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7826 - loss: 1.3638 - val_accuracy: 0.8457 - val_loss: 1.2255 - learning_rate: 0.0010\n",
      "Epoch 26/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7896 - loss: 1.3004 - val_accuracy: 0.8457 - val_loss: 1.1710 - learning_rate: 0.0010\n",
      "Epoch 27/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7633 - loss: 1.2672 - val_accuracy: 0.8457 - val_loss: 1.1187 - learning_rate: 0.0010\n",
      "Epoch 28/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7760 - loss: 1.1986 - val_accuracy: 0.8457 - val_loss: 1.0703 - learning_rate: 0.0010\n",
      "Epoch 29/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8031 - loss: 1.1250 - val_accuracy: 0.8457 - val_loss: 1.0224 - learning_rate: 0.0010\n",
      "Epoch 30/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7893 - loss: 1.1019 - val_accuracy: 0.8457 - val_loss: 0.9792 - learning_rate: 0.0010\n",
      "Epoch 31/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8067 - loss: 1.0487 - val_accuracy: 0.8457 - val_loss: 0.9428 - learning_rate: 0.0010\n",
      "Epoch 32/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8391 - loss: 0.9603 - val_accuracy: 0.8457 - val_loss: 0.9047 - learning_rate: 0.0010\n",
      "Epoch 33/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7991 - loss: 0.9768 - val_accuracy: 0.8457 - val_loss: 0.8699 - learning_rate: 0.0010\n",
      "Epoch 34/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8234 - loss: 0.9057 - val_accuracy: 0.8457 - val_loss: 0.8391 - learning_rate: 0.0010\n",
      "Epoch 35/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8204 - loss: 0.8848 - val_accuracy: 0.8457 - val_loss: 0.8102 - learning_rate: 0.0010\n",
      "Epoch 36/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8035 - loss: 0.8758 - val_accuracy: 0.8457 - val_loss: 0.7857 - learning_rate: 0.0010\n",
      "Epoch 37/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7947 - loss: 0.8676 - val_accuracy: 0.8457 - val_loss: 0.7646 - learning_rate: 0.0010\n",
      "Epoch 38/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7871 - loss: 0.8502 - val_accuracy: 0.8457 - val_loss: 0.7427 - learning_rate: 0.0010\n",
      "Epoch 39/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7907 - loss: 0.8110 - val_accuracy: 0.8457 - val_loss: 0.7245 - learning_rate: 0.0010\n",
      "Epoch 40/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8038 - loss: 0.7795 - val_accuracy: 0.8457 - val_loss: 0.7032 - learning_rate: 0.0010\n",
      "Epoch 41/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8079 - loss: 0.7710 - val_accuracy: 0.8457 - val_loss: 0.6836 - learning_rate: 0.0010\n",
      "Epoch 42/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8286 - loss: 0.7120 - val_accuracy: 0.8457 - val_loss: 0.6647 - learning_rate: 0.0010\n",
      "Epoch 43/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8112 - loss: 0.7283 - val_accuracy: 0.8457 - val_loss: 0.6458 - learning_rate: 0.0010\n",
      "Epoch 44/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8086 - loss: 0.7137 - val_accuracy: 0.8457 - val_loss: 0.6349 - learning_rate: 0.0010\n",
      "Epoch 45/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8107 - loss: 0.7012 - val_accuracy: 0.8457 - val_loss: 0.6222 - learning_rate: 0.0010\n",
      "Epoch 46/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7903 - loss: 0.7066 - val_accuracy: 0.8457 - val_loss: 0.6140 - learning_rate: 0.0010\n",
      "Epoch 47/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7714 - loss: 0.7118 - val_accuracy: 0.8457 - val_loss: 0.6033 - learning_rate: 0.0010\n",
      "Epoch 48/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7942 - loss: 0.6759 - val_accuracy: 0.8457 - val_loss: 0.5936 - learning_rate: 0.0010\n",
      "Epoch 49/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8041 - loss: 0.6530 - val_accuracy: 0.8457 - val_loss: 0.5874 - learning_rate: 0.0010\n",
      "Epoch 50/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7956 - loss: 0.6517 - val_accuracy: 0.8457 - val_loss: 0.5739 - learning_rate: 0.0010\n",
      "Epoch 51/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8267 - loss: 0.6144 - val_accuracy: 0.8457 - val_loss: 0.5695 - learning_rate: 0.0010\n",
      "Epoch 52/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7995 - loss: 0.6410 - val_accuracy: 0.8457 - val_loss: 0.5619 - learning_rate: 0.0010\n",
      "Epoch 53/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8112 - loss: 0.6181 - val_accuracy: 0.8457 - val_loss: 0.5533 - learning_rate: 0.0010\n",
      "Epoch 54/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7937 - loss: 0.6332 - val_accuracy: 0.8457 - val_loss: 0.5526 - learning_rate: 0.0010\n",
      "Epoch 55/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7997 - loss: 0.6065 - val_accuracy: 0.8457 - val_loss: 0.5449 - learning_rate: 0.0010\n",
      "Epoch 56/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7889 - loss: 0.6294 - val_accuracy: 0.8457 - val_loss: 0.5452 - learning_rate: 0.0010\n",
      "Epoch 57/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8067 - loss: 0.5966 - val_accuracy: 0.8457 - val_loss: 0.5385 - learning_rate: 0.0010\n",
      "Epoch 58/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8029 - loss: 0.5923 - val_accuracy: 0.8457 - val_loss: 0.5350 - learning_rate: 0.0010\n",
      "Epoch 59/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.7987 - loss: 0.5989 - val_accuracy: 0.8457 - val_loss: 0.5292 - learning_rate: 0.0010\n",
      "Epoch 60/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7937 - loss: 0.5940 - val_accuracy: 0.8457 - val_loss: 0.5266 - learning_rate: 0.0010\n",
      "Epoch 61/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8058 - loss: 0.5768 - val_accuracy: 0.8457 - val_loss: 0.5219 - learning_rate: 0.0010\n",
      "Epoch 62/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7934 - loss: 0.5958 - val_accuracy: 0.8457 - val_loss: 0.5149 - learning_rate: 0.0010\n",
      "Epoch 63/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7741 - loss: 0.6152 - val_accuracy: 0.8457 - val_loss: 0.5113 - learning_rate: 0.0010\n",
      "Epoch 64/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7726 - loss: 0.6121 - val_accuracy: 0.8457 - val_loss: 0.5033 - learning_rate: 0.0010\n",
      "Epoch 65/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8023 - loss: 0.5736 - val_accuracy: 0.8457 - val_loss: 0.5022 - learning_rate: 0.0010\n",
      "Epoch 66/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8050 - loss: 0.5609 - val_accuracy: 0.8457 - val_loss: 0.4970 - learning_rate: 0.0010\n",
      "Epoch 67/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8051 - loss: 0.5467 - val_accuracy: 0.8457 - val_loss: 0.4978 - learning_rate: 0.0010\n",
      "Epoch 68/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8022 - loss: 0.5592 - val_accuracy: 0.8457 - val_loss: 0.4966 - learning_rate: 0.0010\n",
      "Epoch 69/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8086 - loss: 0.5514 - val_accuracy: 0.8457 - val_loss: 0.4908 - learning_rate: 0.0010\n",
      "Epoch 70/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7956 - loss: 0.5575 - val_accuracy: 0.8457 - val_loss: 0.4841 - learning_rate: 0.0010\n",
      "Epoch 71/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8120 - loss: 0.5360 - val_accuracy: 0.8457 - val_loss: 0.4807 - learning_rate: 0.0010\n",
      "Epoch 72/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8215 - loss: 0.5209 - val_accuracy: 0.8457 - val_loss: 0.4790 - learning_rate: 0.0010\n",
      "Epoch 73/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7990 - loss: 0.5519 - val_accuracy: 0.8457 - val_loss: 0.4775 - learning_rate: 0.0010\n",
      "Epoch 74/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8047 - loss: 0.5350 - val_accuracy: 0.8457 - val_loss: 0.4746 - learning_rate: 0.0010\n",
      "Epoch 75/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7959 - loss: 0.5466 - val_accuracy: 0.8457 - val_loss: 0.4779 - learning_rate: 0.0010\n",
      "Epoch 76/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7914 - loss: 0.5667 - val_accuracy: 0.8457 - val_loss: 0.4754 - learning_rate: 0.0010\n",
      "Epoch 77/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7820 - loss: 0.5536 - val_accuracy: 0.8457 - val_loss: 0.4783 - learning_rate: 0.0010\n",
      "Epoch 78/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8071 - loss: 0.5382 - val_accuracy: 0.8457 - val_loss: 0.4695 - learning_rate: 0.0010\n",
      "Epoch 79/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7900 - loss: 0.5649 - val_accuracy: 0.8457 - val_loss: 0.4706 - learning_rate: 0.0010\n",
      "Epoch 80/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8063 - loss: 0.5350 - val_accuracy: 0.8457 - val_loss: 0.4705 - learning_rate: 0.0010\n",
      "Epoch 81/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7786 - loss: 0.5639 - val_accuracy: 0.8457 - val_loss: 0.4715 - learning_rate: 0.0010\n",
      "Epoch 82/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7949 - loss: 0.5450 - val_accuracy: 0.8457 - val_loss: 0.4720 - learning_rate: 0.0010\n",
      "Epoch 83/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8153 - loss: 0.5130 - val_accuracy: 0.8457 - val_loss: 0.4670 - learning_rate: 0.0010\n",
      "Epoch 84/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8151 - loss: 0.5219 - val_accuracy: 0.8457 - val_loss: 0.4699 - learning_rate: 0.0010\n",
      "Epoch 85/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8093 - loss: 0.5208 - val_accuracy: 0.8457 - val_loss: 0.4698 - learning_rate: 0.0010\n",
      "Epoch 86/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7923 - loss: 0.5556 - val_accuracy: 0.8457 - val_loss: 0.4710 - learning_rate: 0.0010\n",
      "Epoch 87/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7988 - loss: 0.5288 - val_accuracy: 0.8457 - val_loss: 0.4698 - learning_rate: 0.0010\n",
      "Epoch 88/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8186 - loss: 0.5084 - val_accuracy: 0.8457 - val_loss: 0.4673 - learning_rate: 0.0010\n",
      "Epoch 89/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7920 - loss: 0.5452 - val_accuracy: 0.8457 - val_loss: 0.4641 - learning_rate: 0.0010\n",
      "Epoch 90/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8134 - loss: 0.5089 - val_accuracy: 0.8457 - val_loss: 0.4567 - learning_rate: 0.0010\n",
      "Epoch 91/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8011 - loss: 0.5237 - val_accuracy: 0.8457 - val_loss: 0.4668 - learning_rate: 0.0010\n",
      "Epoch 92/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8078 - loss: 0.5229 - val_accuracy: 0.8457 - val_loss: 0.4615 - learning_rate: 0.0010\n",
      "Epoch 93/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7901 - loss: 0.5446 - val_accuracy: 0.8457 - val_loss: 0.4601 - learning_rate: 0.0010\n",
      "Epoch 94/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8308 - loss: 0.4850 - val_accuracy: 0.8457 - val_loss: 0.4582 - learning_rate: 0.0010\n",
      "Epoch 95/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8063 - loss: 0.5121 - val_accuracy: 0.8457 - val_loss: 0.4589 - learning_rate: 0.0010\n",
      "Epoch 96/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8028 - loss: 0.5288 - val_accuracy: 0.8457 - val_loss: 0.4661 - learning_rate: 0.0010\n",
      "Epoch 97/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8124 - loss: 0.5009 - val_accuracy: 0.8457 - val_loss: 0.4652 - learning_rate: 0.0010\n",
      "Epoch 98/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8210 - loss: 0.4876 - val_accuracy: 0.8457 - val_loss: 0.4628 - learning_rate: 0.0010\n",
      "Epoch 99/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7914 - loss: 0.5327 - val_accuracy: 0.8457 - val_loss: 0.4586 - learning_rate: 0.0010\n",
      "Epoch 100/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8177 - loss: 0.4937 - val_accuracy: 0.8457 - val_loss: 0.4588 - learning_rate: 0.0010\n",
      "Epoch 101/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8145 - loss: 0.5078 - val_accuracy: 0.8457 - val_loss: 0.4588 - learning_rate: 5.0000e-04\n",
      "Epoch 102/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7959 - loss: 0.5239 - val_accuracy: 0.8457 - val_loss: 0.4599 - learning_rate: 5.0000e-04\n",
      "Epoch 103/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7818 - loss: 0.5460 - val_accuracy: 0.8457 - val_loss: 0.4581 - learning_rate: 5.0000e-04\n",
      "Epoch 104/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8035 - loss: 0.5126 - val_accuracy: 0.8457 - val_loss: 0.4585 - learning_rate: 5.0000e-04\n",
      "Epoch 105/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8096 - loss: 0.5107 - val_accuracy: 0.8457 - val_loss: 0.4584 - learning_rate: 5.0000e-04\n",
      "Fold 4 - Validation Loss: 0.4567, Validation Accuracy: 0.8457\n",
      "Training on Fold 5/5...\n",
      "Epoch 1/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 104ms/step - accuracy: 0.4627 - loss: 8.1620 - val_accuracy: 0.7926 - val_loss: 6.4792 - learning_rate: 0.0010\n",
      "Epoch 2/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5377 - loss: 6.2296 - val_accuracy: 0.7926 - val_loss: 5.1551 - learning_rate: 0.0010\n",
      "Epoch 3/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5625 - loss: 4.9959 - val_accuracy: 0.7926 - val_loss: 4.3418 - learning_rate: 0.0010\n",
      "Epoch 4/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6071 - loss: 4.2745 - val_accuracy: 0.7926 - val_loss: 3.8079 - learning_rate: 0.0010\n",
      "Epoch 5/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.6451 - loss: 3.7748 - val_accuracy: 0.7926 - val_loss: 3.4458 - learning_rate: 0.0010\n",
      "Epoch 6/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6602 - loss: 3.4238 - val_accuracy: 0.7926 - val_loss: 3.1581 - learning_rate: 0.0010\n",
      "Epoch 7/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6765 - loss: 3.1448 - val_accuracy: 0.7926 - val_loss: 2.9219 - learning_rate: 0.0010\n",
      "Epoch 8/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7191 - loss: 2.9202 - val_accuracy: 0.7926 - val_loss: 2.7132 - learning_rate: 0.0010\n",
      "Epoch 9/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7636 - loss: 2.6983 - val_accuracy: 0.7926 - val_loss: 2.5224 - learning_rate: 0.0010\n",
      "Epoch 10/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7902 - loss: 2.4925 - val_accuracy: 0.7926 - val_loss: 2.3545 - learning_rate: 0.0010\n",
      "Epoch 11/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7759 - loss: 2.3111 - val_accuracy: 0.7926 - val_loss: 2.1929 - learning_rate: 0.0010\n",
      "Epoch 12/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7662 - loss: 2.2051 - val_accuracy: 0.7926 - val_loss: 2.0457 - learning_rate: 0.0010\n",
      "Epoch 13/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7875 - loss: 2.0105 - val_accuracy: 0.7926 - val_loss: 1.9118 - learning_rate: 0.0010\n",
      "Epoch 14/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7694 - loss: 1.9186 - val_accuracy: 0.7926 - val_loss: 1.7915 - learning_rate: 0.0010\n",
      "Epoch 15/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7853 - loss: 1.7571 - val_accuracy: 0.7926 - val_loss: 1.6804 - learning_rate: 0.0010\n",
      "Epoch 16/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7785 - loss: 1.6968 - val_accuracy: 0.7926 - val_loss: 1.5789 - learning_rate: 0.0010\n",
      "Epoch 17/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7918 - loss: 1.5700 - val_accuracy: 0.7926 - val_loss: 1.4855 - learning_rate: 0.0010\n",
      "Epoch 18/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7886 - loss: 1.4776 - val_accuracy: 0.7926 - val_loss: 1.3982 - learning_rate: 0.0010\n",
      "Epoch 19/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7945 - loss: 1.4109 - val_accuracy: 0.7926 - val_loss: 1.3196 - learning_rate: 0.0010\n",
      "Epoch 20/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8148 - loss: 1.2774 - val_accuracy: 0.7926 - val_loss: 1.2492 - learning_rate: 0.0010\n",
      "Epoch 21/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8135 - loss: 1.2223 - val_accuracy: 0.7926 - val_loss: 1.1817 - learning_rate: 0.0010\n",
      "Epoch 22/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8301 - loss: 1.1203 - val_accuracy: 0.7926 - val_loss: 1.1196 - learning_rate: 0.0010\n",
      "Epoch 23/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8089 - loss: 1.1038 - val_accuracy: 0.7926 - val_loss: 1.0662 - learning_rate: 0.0010\n",
      "Epoch 24/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8269 - loss: 1.0044 - val_accuracy: 0.7926 - val_loss: 1.0200 - learning_rate: 0.0010\n",
      "Epoch 25/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8078 - loss: 0.9932 - val_accuracy: 0.7926 - val_loss: 0.9756 - learning_rate: 0.0010\n",
      "Epoch 26/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8152 - loss: 0.9554 - val_accuracy: 0.7926 - val_loss: 0.9352 - learning_rate: 0.0010\n",
      "Epoch 27/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7901 - loss: 0.9394 - val_accuracy: 0.7926 - val_loss: 0.8988 - learning_rate: 0.0010\n",
      "Epoch 28/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7903 - loss: 0.9047 - val_accuracy: 0.7926 - val_loss: 0.8695 - learning_rate: 0.0010\n",
      "Epoch 29/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8237 - loss: 0.8240 - val_accuracy: 0.7926 - val_loss: 0.8390 - learning_rate: 0.0010\n",
      "Epoch 30/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7739 - loss: 0.8542 - val_accuracy: 0.7926 - val_loss: 0.8128 - learning_rate: 0.0010\n",
      "Epoch 31/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8115 - loss: 0.7955 - val_accuracy: 0.7926 - val_loss: 0.7882 - learning_rate: 0.0010\n",
      "Epoch 32/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8276 - loss: 0.7698 - val_accuracy: 0.7926 - val_loss: 0.7648 - learning_rate: 0.0010\n",
      "Epoch 33/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8194 - loss: 0.7321 - val_accuracy: 0.7926 - val_loss: 0.7481 - learning_rate: 0.0010\n",
      "Epoch 34/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8068 - loss: 0.7393 - val_accuracy: 0.7926 - val_loss: 0.7278 - learning_rate: 0.0010\n",
      "Epoch 35/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8235 - loss: 0.6958 - val_accuracy: 0.7926 - val_loss: 0.7087 - learning_rate: 0.0010\n",
      "Epoch 36/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8230 - loss: 0.6929 - val_accuracy: 0.7926 - val_loss: 0.6986 - learning_rate: 0.0010\n",
      "Epoch 37/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8108 - loss: 0.6639 - val_accuracy: 0.7926 - val_loss: 0.6934 - learning_rate: 0.0010\n",
      "Epoch 38/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8008 - loss: 0.6774 - val_accuracy: 0.7926 - val_loss: 0.6753 - learning_rate: 0.0010\n",
      "Epoch 39/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8220 - loss: 0.6347 - val_accuracy: 0.7926 - val_loss: 0.6597 - learning_rate: 0.0010\n",
      "Epoch 40/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8148 - loss: 0.6234 - val_accuracy: 0.7926 - val_loss: 0.6538 - learning_rate: 0.0010\n",
      "Epoch 41/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7934 - loss: 0.6612 - val_accuracy: 0.7926 - val_loss: 0.6397 - learning_rate: 0.0010\n",
      "Epoch 42/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8198 - loss: 0.6146 - val_accuracy: 0.7926 - val_loss: 0.6328 - learning_rate: 0.0010\n",
      "Epoch 43/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8082 - loss: 0.6115 - val_accuracy: 0.7926 - val_loss: 0.6214 - learning_rate: 0.0010\n",
      "Epoch 44/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7988 - loss: 0.6364 - val_accuracy: 0.7926 - val_loss: 0.6182 - learning_rate: 0.0010\n",
      "Epoch 45/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8213 - loss: 0.5882 - val_accuracy: 0.7926 - val_loss: 0.6126 - learning_rate: 0.0010\n",
      "Epoch 46/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7955 - loss: 0.6134 - val_accuracy: 0.7926 - val_loss: 0.6003 - learning_rate: 0.0010\n",
      "Epoch 47/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8108 - loss: 0.5893 - val_accuracy: 0.7926 - val_loss: 0.5977 - learning_rate: 0.0010\n",
      "Epoch 48/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8266 - loss: 0.5530 - val_accuracy: 0.7926 - val_loss: 0.5910 - learning_rate: 0.0010\n",
      "Epoch 49/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7925 - loss: 0.6265 - val_accuracy: 0.7926 - val_loss: 0.5916 - learning_rate: 0.0010\n",
      "Epoch 50/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8227 - loss: 0.5516 - val_accuracy: 0.7926 - val_loss: 0.5892 - learning_rate: 0.0010\n",
      "Epoch 51/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8069 - loss: 0.5729 - val_accuracy: 0.7926 - val_loss: 0.5839 - learning_rate: 0.0010\n",
      "Epoch 52/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8205 - loss: 0.5515 - val_accuracy: 0.7926 - val_loss: 0.5748 - learning_rate: 0.0010\n",
      "Epoch 53/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7903 - loss: 0.5804 - val_accuracy: 0.7926 - val_loss: 0.5675 - learning_rate: 0.0010\n",
      "Epoch 54/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8179 - loss: 0.5498 - val_accuracy: 0.7926 - val_loss: 0.5644 - learning_rate: 0.0010\n",
      "Epoch 55/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7975 - loss: 0.5646 - val_accuracy: 0.7926 - val_loss: 0.5604 - learning_rate: 0.0010\n",
      "Epoch 56/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8181 - loss: 0.5352 - val_accuracy: 0.7926 - val_loss: 0.5622 - learning_rate: 0.0010\n",
      "Epoch 57/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8218 - loss: 0.5215 - val_accuracy: 0.7926 - val_loss: 0.5606 - learning_rate: 0.0010\n",
      "Epoch 58/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8165 - loss: 0.5302 - val_accuracy: 0.7926 - val_loss: 0.5559 - learning_rate: 0.0010\n",
      "Epoch 59/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8123 - loss: 0.5349 - val_accuracy: 0.7926 - val_loss: 0.5524 - learning_rate: 0.0010\n",
      "Epoch 60/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8130 - loss: 0.5301 - val_accuracy: 0.7926 - val_loss: 0.5550 - learning_rate: 0.0010\n",
      "Epoch 61/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8115 - loss: 0.5312 - val_accuracy: 0.7926 - val_loss: 0.5590 - learning_rate: 0.0010\n",
      "Epoch 62/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8219 - loss: 0.5192 - val_accuracy: 0.7926 - val_loss: 0.5529 - learning_rate: 0.0010\n",
      "Epoch 63/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8023 - loss: 0.5404 - val_accuracy: 0.7926 - val_loss: 0.5471 - learning_rate: 0.0010\n",
      "Epoch 64/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8234 - loss: 0.5271 - val_accuracy: 0.7926 - val_loss: 0.5484 - learning_rate: 0.0010\n",
      "Epoch 65/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8064 - loss: 0.5361 - val_accuracy: 0.7926 - val_loss: 0.5463 - learning_rate: 0.0010\n",
      "Epoch 66/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8236 - loss: 0.5086 - val_accuracy: 0.7926 - val_loss: 0.5412 - learning_rate: 0.0010\n",
      "Epoch 67/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8040 - loss: 0.5309 - val_accuracy: 0.7926 - val_loss: 0.5429 - learning_rate: 0.0010\n",
      "Epoch 68/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7907 - loss: 0.5468 - val_accuracy: 0.7926 - val_loss: 0.5456 - learning_rate: 0.0010\n",
      "Epoch 69/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8049 - loss: 0.5319 - val_accuracy: 0.7926 - val_loss: 0.5424 - learning_rate: 0.0010\n",
      "Epoch 70/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7947 - loss: 0.5498 - val_accuracy: 0.7926 - val_loss: 0.5419 - learning_rate: 0.0010\n",
      "Epoch 71/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8196 - loss: 0.5212 - val_accuracy: 0.7926 - val_loss: 0.5394 - learning_rate: 0.0010\n",
      "Epoch 72/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8017 - loss: 0.5266 - val_accuracy: 0.7926 - val_loss: 0.5470 - learning_rate: 0.0010\n",
      "Epoch 73/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7961 - loss: 0.5427 - val_accuracy: 0.7926 - val_loss: 0.5351 - learning_rate: 0.0010\n",
      "Epoch 74/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7975 - loss: 0.5514 - val_accuracy: 0.7926 - val_loss: 0.5437 - learning_rate: 0.0010\n",
      "Epoch 75/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8098 - loss: 0.5299 - val_accuracy: 0.7926 - val_loss: 0.5374 - learning_rate: 0.0010\n",
      "Epoch 76/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8043 - loss: 0.5439 - val_accuracy: 0.7926 - val_loss: 0.5390 - learning_rate: 0.0010\n",
      "Epoch 77/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8202 - loss: 0.5161 - val_accuracy: 0.7926 - val_loss: 0.5367 - learning_rate: 0.0010\n",
      "Epoch 78/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8078 - loss: 0.5324 - val_accuracy: 0.7926 - val_loss: 0.5390 - learning_rate: 0.0010\n",
      "Epoch 79/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8053 - loss: 0.5231 - val_accuracy: 0.7926 - val_loss: 0.5402 - learning_rate: 0.0010\n",
      "Epoch 80/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8118 - loss: 0.5071 - val_accuracy: 0.7926 - val_loss: 0.5315 - learning_rate: 0.0010\n",
      "Epoch 81/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8032 - loss: 0.5203 - val_accuracy: 0.7926 - val_loss: 0.5331 - learning_rate: 0.0010\n",
      "Epoch 82/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8263 - loss: 0.4900 - val_accuracy: 0.7926 - val_loss: 0.5336 - learning_rate: 0.0010\n",
      "Epoch 83/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8146 - loss: 0.4995 - val_accuracy: 0.7926 - val_loss: 0.5318 - learning_rate: 0.0010\n",
      "Epoch 84/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8355 - loss: 0.4865 - val_accuracy: 0.7926 - val_loss: 0.5356 - learning_rate: 0.0010\n",
      "Epoch 85/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8104 - loss: 0.5178 - val_accuracy: 0.7926 - val_loss: 0.5314 - learning_rate: 0.0010\n",
      "Epoch 86/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8039 - loss: 0.5239 - val_accuracy: 0.7926 - val_loss: 0.5363 - learning_rate: 0.0010\n",
      "Epoch 87/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8365 - loss: 0.4789 - val_accuracy: 0.7926 - val_loss: 0.5270 - learning_rate: 0.0010\n",
      "Epoch 88/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8289 - loss: 0.4893 - val_accuracy: 0.7926 - val_loss: 0.5354 - learning_rate: 0.0010\n",
      "Epoch 89/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8373 - loss: 0.4749 - val_accuracy: 0.7926 - val_loss: 0.5290 - learning_rate: 0.0010\n",
      "Epoch 90/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8158 - loss: 0.5098 - val_accuracy: 0.7926 - val_loss: 0.5256 - learning_rate: 0.0010\n",
      "Epoch 91/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8054 - loss: 0.5151 - val_accuracy: 0.7926 - val_loss: 0.5263 - learning_rate: 0.0010\n",
      "Epoch 92/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8197 - loss: 0.5001 - val_accuracy: 0.7926 - val_loss: 0.5321 - learning_rate: 0.0010\n",
      "Epoch 93/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8019 - loss: 0.5196 - val_accuracy: 0.7926 - val_loss: 0.5328 - learning_rate: 0.0010\n",
      "Epoch 94/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8101 - loss: 0.5079 - val_accuracy: 0.7926 - val_loss: 0.5235 - learning_rate: 0.0010\n",
      "Epoch 95/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7913 - loss: 0.5450 - val_accuracy: 0.7926 - val_loss: 0.5255 - learning_rate: 0.0010\n",
      "Epoch 96/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8062 - loss: 0.5082 - val_accuracy: 0.7926 - val_loss: 0.5226 - learning_rate: 0.0010\n",
      "Epoch 97/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8260 - loss: 0.4692 - val_accuracy: 0.7926 - val_loss: 0.5224 - learning_rate: 0.0010\n",
      "Epoch 98/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8189 - loss: 0.4921 - val_accuracy: 0.7926 - val_loss: 0.5232 - learning_rate: 0.0010\n",
      "Epoch 99/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8117 - loss: 0.5047 - val_accuracy: 0.7926 - val_loss: 0.5223 - learning_rate: 0.0010\n",
      "Epoch 100/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8286 - loss: 0.4755 - val_accuracy: 0.7926 - val_loss: 0.5236 - learning_rate: 0.0010\n",
      "Epoch 101/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7922 - loss: 0.5286 - val_accuracy: 0.7926 - val_loss: 0.5292 - learning_rate: 0.0010\n",
      "Epoch 102/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8082 - loss: 0.5190 - val_accuracy: 0.7926 - val_loss: 0.5288 - learning_rate: 0.0010\n",
      "Epoch 103/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8057 - loss: 0.5192 - val_accuracy: 0.7926 - val_loss: 0.5267 - learning_rate: 0.0010\n",
      "Epoch 104/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8025 - loss: 0.5179 - val_accuracy: 0.7926 - val_loss: 0.5219 - learning_rate: 0.0010\n",
      "Epoch 105/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8051 - loss: 0.5125 - val_accuracy: 0.7926 - val_loss: 0.5220 - learning_rate: 0.0010\n",
      "Epoch 106/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8015 - loss: 0.5151 - val_accuracy: 0.7926 - val_loss: 0.5212 - learning_rate: 0.0010\n",
      "Epoch 107/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8104 - loss: 0.5047 - val_accuracy: 0.7926 - val_loss: 0.5200 - learning_rate: 0.0010\n",
      "Epoch 108/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8023 - loss: 0.5157 - val_accuracy: 0.7926 - val_loss: 0.5228 - learning_rate: 0.0010\n",
      "Epoch 109/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7915 - loss: 0.5364 - val_accuracy: 0.7926 - val_loss: 0.5207 - learning_rate: 0.0010\n",
      "Epoch 110/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8343 - loss: 0.4652 - val_accuracy: 0.7926 - val_loss: 0.5242 - learning_rate: 0.0010\n",
      "Epoch 111/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8220 - loss: 0.4983 - val_accuracy: 0.7926 - val_loss: 0.5256 - learning_rate: 0.0010\n",
      "Epoch 112/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8314 - loss: 0.4806 - val_accuracy: 0.7926 - val_loss: 0.5352 - learning_rate: 0.0010\n",
      "Epoch 113/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8144 - loss: 0.5028 - val_accuracy: 0.7926 - val_loss: 0.5393 - learning_rate: 0.0010\n",
      "Epoch 114/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8226 - loss: 0.4940 - val_accuracy: 0.7926 - val_loss: 0.5276 - learning_rate: 0.0010\n",
      "Epoch 115/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8080 - loss: 0.5160 - val_accuracy: 0.7926 - val_loss: 0.5204 - learning_rate: 0.0010\n",
      "Epoch 116/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8313 - loss: 0.4722 - val_accuracy: 0.7926 - val_loss: 0.5196 - learning_rate: 0.0010\n",
      "Epoch 117/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8157 - loss: 0.4936 - val_accuracy: 0.7926 - val_loss: 0.5188 - learning_rate: 0.0010\n",
      "Epoch 118/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8218 - loss: 0.4885 - val_accuracy: 0.7926 - val_loss: 0.5215 - learning_rate: 0.0010\n",
      "Epoch 119/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8072 - loss: 0.5015 - val_accuracy: 0.7926 - val_loss: 0.5195 - learning_rate: 0.0010\n",
      "Epoch 120/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8167 - loss: 0.4958 - val_accuracy: 0.7926 - val_loss: 0.5178 - learning_rate: 0.0010\n",
      "Epoch 121/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8034 - loss: 0.5143 - val_accuracy: 0.7926 - val_loss: 0.5214 - learning_rate: 0.0010\n",
      "Epoch 122/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8252 - loss: 0.4842 - val_accuracy: 0.7926 - val_loss: 0.5295 - learning_rate: 0.0010\n",
      "Epoch 123/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7974 - loss: 0.5153 - val_accuracy: 0.7926 - val_loss: 0.5308 - learning_rate: 0.0010\n",
      "Epoch 124/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7710 - loss: 0.5625 - val_accuracy: 0.7926 - val_loss: 0.5300 - learning_rate: 0.0010\n",
      "Epoch 125/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8150 - loss: 0.5019 - val_accuracy: 0.7926 - val_loss: 0.5220 - learning_rate: 0.0010\n",
      "Epoch 126/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8173 - loss: 0.5017 - val_accuracy: 0.7926 - val_loss: 0.5273 - learning_rate: 0.0010\n",
      "Epoch 127/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7968 - loss: 0.5409 - val_accuracy: 0.7926 - val_loss: 0.5348 - learning_rate: 0.0010\n",
      "Epoch 128/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8016 - loss: 0.5207 - val_accuracy: 0.7926 - val_loss: 0.5313 - learning_rate: 0.0010\n",
      "Epoch 129/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8148 - loss: 0.5011 - val_accuracy: 0.7926 - val_loss: 0.5249 - learning_rate: 0.0010\n",
      "Epoch 130/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8200 - loss: 0.4844 - val_accuracy: 0.7926 - val_loss: 0.5187 - learning_rate: 0.0010\n",
      "Epoch 131/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8124 - loss: 0.4994 - val_accuracy: 0.7926 - val_loss: 0.5177 - learning_rate: 5.0000e-04\n",
      "Epoch 132/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8227 - loss: 0.4817 - val_accuracy: 0.7926 - val_loss: 0.5206 - learning_rate: 5.0000e-04\n",
      "Epoch 133/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8091 - loss: 0.4937 - val_accuracy: 0.7926 - val_loss: 0.5185 - learning_rate: 5.0000e-04\n",
      "Epoch 134/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8134 - loss: 0.4999 - val_accuracy: 0.7926 - val_loss: 0.5194 - learning_rate: 5.0000e-04\n",
      "Epoch 135/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8186 - loss: 0.4904 - val_accuracy: 0.7926 - val_loss: 0.5194 - learning_rate: 5.0000e-04\n",
      "Epoch 136/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8004 - loss: 0.5149 - val_accuracy: 0.7926 - val_loss: 0.5180 - learning_rate: 5.0000e-04\n",
      "Epoch 137/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8211 - loss: 0.4871 - val_accuracy: 0.7926 - val_loss: 0.5211 - learning_rate: 5.0000e-04\n",
      "Epoch 138/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8072 - loss: 0.5016 - val_accuracy: 0.7926 - val_loss: 0.5182 - learning_rate: 5.0000e-04\n",
      "Epoch 139/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8291 - loss: 0.4668 - val_accuracy: 0.7926 - val_loss: 0.5182 - learning_rate: 5.0000e-04\n",
      "Epoch 140/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8315 - loss: 0.4702 - val_accuracy: 0.7926 - val_loss: 0.5197 - learning_rate: 5.0000e-04\n",
      "Epoch 141/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8192 - loss: 0.4856 - val_accuracy: 0.7926 - val_loss: 0.5201 - learning_rate: 2.5000e-04\n",
      "Epoch 142/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7883 - loss: 0.5263 - val_accuracy: 0.7926 - val_loss: 0.5193 - learning_rate: 2.5000e-04\n",
      "Epoch 143/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7799 - loss: 0.5400 - val_accuracy: 0.7926 - val_loss: 0.5190 - learning_rate: 2.5000e-04\n",
      "Epoch 144/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8433 - loss: 0.4532 - val_accuracy: 0.7926 - val_loss: 0.5189 - learning_rate: 2.5000e-04\n",
      "Epoch 145/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8025 - loss: 0.5104 - val_accuracy: 0.7926 - val_loss: 0.5169 - learning_rate: 2.5000e-04\n",
      "Epoch 146/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8260 - loss: 0.4702 - val_accuracy: 0.7926 - val_loss: 0.5160 - learning_rate: 2.5000e-04\n",
      "Epoch 147/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8131 - loss: 0.4981 - val_accuracy: 0.7926 - val_loss: 0.5164 - learning_rate: 2.5000e-04\n",
      "Epoch 148/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7963 - loss: 0.5179 - val_accuracy: 0.7926 - val_loss: 0.5164 - learning_rate: 2.5000e-04\n",
      "Epoch 149/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8115 - loss: 0.5024 - val_accuracy: 0.7926 - val_loss: 0.5189 - learning_rate: 2.5000e-04\n",
      "Epoch 150/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8056 - loss: 0.5071 - val_accuracy: 0.7926 - val_loss: 0.5198 - learning_rate: 2.5000e-04\n",
      "Fold 5 - Validation Loss: 0.5160, Validation Accuracy: 0.7926\n",
      "\n",
      "Average Validation Loss: 0.5013\n",
      "Average Validation Accuracy: 0.8100\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import numpy as np\n",
    "\n",
    "# Define k for K-Fold\n",
    "k = 5\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# Store fold results\n",
    "fold_accuracies = []\n",
    "fold_losses = []\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "fold = 1\n",
    "for train_index, val_index in kf.split(X_pad):\n",
    "    print(f\"Training on Fold {fold}/{k}...\")\n",
    "    \n",
    "    # Split data into training and validation sets for this fold\n",
    "    X_train, X_val = X_pad[train_index], X_pad[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    \n",
    "    structured_input_train = X_train[:, 0, :]\n",
    "    structured_input_val = X_val[:, 0, :]\n",
    "\n",
    "    # Create a new instance of the model for each fold\n",
    "    model = create_han_model((1, 3))\n",
    "    \n",
    "    # Define callbacks\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=0.00001)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        [X_train, structured_input_train], y_train,\n",
    "        epochs=150, batch_size=32,\n",
    "        validation_data=([X_val, structured_input_val], y_val),\n",
    "        callbacks=[early_stopping, reduce_lr],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Evaluate on the validation set\n",
    "    val_loss, val_accuracy = model.evaluate([X_val, structured_input_val], y_val, verbose=0)\n",
    "    print(f\"Fold {fold} - Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    # Store results\n",
    "    fold_losses.append(val_loss)\n",
    "    fold_accuracies.append(val_accuracy)\n",
    "    \n",
    "    fold += 1\n",
    "\n",
    "# Compute the average performance\n",
    "average_loss = np.mean(fold_losses)\n",
    "average_accuracy = np.mean(fold_accuracies)\n",
    "print(f\"\\nAverage Validation Loss: {average_loss:.4f}\")\n",
    "print(f\"Average Validation Accuracy: {average_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "dcf2af6e-7184-42b4-80a4-d5fa25701429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n"
     ]
    }
   ],
   "source": [
    "# Generate predictions for the test set\n",
    "predictions = model.predict([X_val, structured_input_val])\n",
    "\n",
    "# Threshold for binary classification\n",
    "threshold = 0.5\n",
    "murmur_present_predictions = (predictions > threshold).astype(int)\n",
    "\n",
    "# For multi-class predictions (e.g., severity, type), you'd have additional models or multi-output model.\n",
    "# Here is an example assuming you have these predictions ready:\n",
    "severity_predictions = [\"Grade III\" for _ in range(len(predictions))]  # Placeholder\n",
    "type_predictions = [\"Systolic\" for _ in range(len(predictions))]  # Placeholder\n",
    "location_predictions = [\"Mitral Valve\" for _ in range(len(predictions))]  # Placeholder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0acfeaa3-6983-46f1-a03a-dcbb1b9c3979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Validation Loss: 0.5013\n",
      "Average Validation Accuracy: 0.8100\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Plot Validation Loss and Accuracy for each fold\n",
    "folds = range(1, k + 1)\n",
    "\n",
    "# Plot Validation Loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(folds, fold_losses, marker='o', linestyle='-', color='b')\n",
    "plt.title('Validation Loss Across Folds')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.xticks(folds)\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot Validation Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(folds, fold_accuracies, marker='o', linestyle='-', color='g')\n",
    "plt.title('Validation Accuracy Across Folds')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.xticks(folds)\n",
    "plt.grid(True)\n",
    "\n",
    "# Add a super title and show the plot\n",
    "plt.suptitle('K-Fold Cross-Validation Results', fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()\n",
    "\n",
    "# Print average performance\n",
    "print(f\"Average Validation Loss: {np.mean(fold_losses):.4f}\")\n",
    "print(f\"Average Validation Accuracy: {np.mean(fold_accuracies):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa98e3a-7053-409d-816a-ef3b9159ff7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Fold 1/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nidhi\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\nn.py:827: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Train Loss: 0.8682, Train Accuracy: 0.8114\n",
      "Fold 1 - Validation Loss: 0.8847, Validation Accuracy: 0.8042\n",
      "Training on Fold 2/5...\n",
      "Fold 2 - Train Loss: 0.9166, Train Accuracy: 0.8061\n",
      "Fold 2 - Validation Loss: 0.8894, Validation Accuracy: 0.8254\n",
      "Training on Fold 3/5...\n",
      "Fold 3 - Train Loss: 0.9709, Train Accuracy: 0.8170\n",
      "Fold 3 - Validation Loss: 1.0222, Validation Accuracy: 0.7819\n",
      "Training on Fold 4/5...\n",
      "Fold 4 - Train Loss: 0.8519, Train Accuracy: 0.8011\n",
      "Fold 4 - Validation Loss: 0.7900, Validation Accuracy: 0.8457\n",
      "Training on Fold 5/5...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Number of folds\n",
    "k = 5\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "fold_train_losses = []\n",
    "fold_train_accuracies = []\n",
    "fold_losses = []\n",
    "fold_accuracies = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_pad)):\n",
    "    print(f\"Training on Fold {fold + 1}/{k}...\")\n",
    "    \n",
    "    # Prepare training and validation data\n",
    "    X_train, X_val = X_pad[train_idx], X_pad[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "    structured_input_train = X_train[:, 0, :]  # Structured inputs for training\n",
    "    structured_input_val = X_val[:, 0, :]      # Structured inputs for validation\n",
    "\n",
    "    # Create a new model instance for each fold\n",
    "    model = create_han_model(input_shape=(X_pad.shape[1], X_pad.shape[2]))\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        [X_train, structured_input_train], y_train,\n",
    "        validation_data=([X_val, structured_input_val], y_val),\n",
    "        epochs=30,  # Use a small number of epochs for k-fold cross-validation\n",
    "        batch_size=32,\n",
    "        callbacks=[early_stopping, reduce_lr],\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # Record metrics for this fold\n",
    "    train_loss, train_accuracy = model.evaluate([X_train, structured_input_train], y_train, verbose=0)\n",
    "    val_loss, val_accuracy = model.evaluate([X_val, structured_input_val], y_val, verbose=0)\n",
    "    \n",
    "    fold_train_losses.append(train_loss)\n",
    "    fold_train_accuracies.append(train_accuracy)\n",
    "    fold_losses.append(val_loss)\n",
    "    fold_accuracies.append(val_accuracy)\n",
    "\n",
    "    print(f\"Fold {fold + 1} - Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Fold {fold + 1} - Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "# Plot training and validation metrics\n",
    "folds = range(1, k + 1)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "# Plot Training and Validation Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(folds, fold_train_losses, marker='o', linestyle='-', color='orange', label='Training Loss')\n",
    "plt.plot(folds, fold_losses, marker='o', linestyle='-', color='blue', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss Across Folds')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Loss')\n",
    "plt.xticks(folds)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot Training and Validation Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(folds, fold_train_accuracies, marker='o', linestyle='-', color='green', label='Training Accuracy')\n",
    "plt.plot(folds, fold_accuracies, marker='o', linestyle='-', color='red', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy Across Folds')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(folds)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Add a super title and show the plot\n",
    "plt.suptitle('K-Fold Cross-Validation Results: Training vs Validation', fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()\n",
    "\n",
    "# Print average performance\n",
    "print(f\"Average Training Loss: {np.mean(fold_train_losses):.4f}\")\n",
    "print(f\"Average Validation Loss: {np.mean(fold_losses):.4f}\")\n",
    "print(f\"Average Training Accuracy: {np.mean(fold_train_accuracies):.4f}\")\n",
    "print(f\"Average Validation Accuracy: {np.mean(fold_accuracies):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "e47e8b82-d570-418a-a24e-1cd36f20e5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Patient 1 raw prediction: [0.277186]\n",
      "Patient 2 raw prediction: [0.277186]\n",
      "Patient 3 raw prediction: [0.2056948]\n",
      "Patient 4 raw prediction: [0.2056948]\n",
      "Patient 5 raw prediction: [0.277186]\n",
      "Patient 1 murmur present prediction: [0]\n",
      "Patient 2 murmur present prediction: [0]\n",
      "Patient 3 murmur present prediction: [0]\n",
      "Patient 4 murmur present prediction: [0]\n",
      "Patient 5 murmur present prediction: [0]\n",
      "Patient 1 original murmur: Present\n",
      "Patient 1 predicted murmur: Absent\n",
      "Patient 2 original murmur: Present\n",
      "Patient 2 predicted murmur: Absent\n",
      "Patient 3 original murmur: Absent\n",
      "Patient 3 predicted murmur: Absent\n",
      "Patient 4 original murmur: Absent\n",
      "Patient 4 predicted murmur: Absent\n",
      "Patient 5 original murmur: Absent\n",
      "Patient 5 predicted murmur: Absent\n",
      "{'Patient ID': 13918, 'Murmur Present': False, 'Severity': 'N/A', 'Type': 'N/A', 'Most Audible Location': 'N/A', 'Associated Conditions': 'None'}\n"
     ]
    }
   ],
   "source": [
    "# Generate raw predictions for the validation set\n",
    "raw_predictions = model.predict([X_val, structured_input_val])\n",
    "\n",
    "# Print a few raw predictions to inspect\n",
    "for i in range(5):  # Adjust the range as needed\n",
    "    print(f\"Patient {i+1} raw prediction: {raw_predictions[i]}\")\n",
    "# Threshold for binary classification\n",
    "threshold = 0.5\n",
    "murmur_present_predictions = (raw_predictions > threshold).astype(int)\n",
    "\n",
    "# Print the binary classification outcomes\n",
    "for i in range(5):  # Adjust the range as needed\n",
    "    print(f\"Patient {i+1} murmur present prediction: {murmur_present_predictions[i]}\")\n",
    "# Print original and predicted values for a few samples\n",
    "for i in range(5):  # Adjust the range as needed\n",
    "    print(f\"Patient {i+1} original murmur: {df.iloc[i]['Murmur']}\")\n",
    "    print(f\"Patient {i+1} predicted murmur: {'Present' if murmur_present_predictions[i][0] else 'Absent'}\")\n",
    "# Generate reports based on model predictions\n",
    "reports = []\n",
    "for i in range(len(raw_predictions)):\n",
    "    patient_id = df.iloc[i]['Patient ID']  # Assuming 'Patient ID' column exists\n",
    "    murmur_present = bool(murmur_present_predictions[i][0])\n",
    "    \n",
    "    if murmur_present:\n",
    "        severity = severity_predictions[i]\n",
    "        murmur_type = type_predictions[i]\n",
    "        location = location_predictions[i]\n",
    "        condition = map_to_condition(location, severity, murmur_type)\n",
    "    else:\n",
    "        severity = \"N/A\"\n",
    "        murmur_type = \"N/A\"\n",
    "        location = \"N/A\"\n",
    "        condition = \"None\"\n",
    "    \n",
    "    report = generate_patient_report(\n",
    "        patient_id=patient_id,\n",
    "        murmur_present=murmur_present,\n",
    "        severity=severity,\n",
    "        murmur_type=murmur_type,\n",
    "        location=location,\n",
    "        condition=condition\n",
    "    )\n",
    "    reports.append(report)\n",
    "\n",
    "# Print a sample report for verification\n",
    "print(reports[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4029fc47-f833-40aa-b999-2804ffc38e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "def create_han_model(input_shape):\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Word-Level Bi-LSTM Layer with Dropout and BatchNormalization\n",
    "    word_lstm = layers.Bidirectional(layers.LSTM(128, return_sequences=True, dropout=0.2))(input_layer)\n",
    "    word_lstm = BatchNormalization()(word_lstm)\n",
    "    \n",
    "    # Word-Level Attention Layer\n",
    "    word_attention = layers.Attention(use_scale=True)([word_lstm, word_lstm])\n",
    "    word_attention_output = layers.GlobalAveragePooling1D()(word_attention)\n",
    "\n",
    "    # Document-Level Bi-LSTM Layer with Dropout and BatchNormalization\n",
    "    document_lstm = layers.Bidirectional(layers.LSTM(64, return_sequences=True, dropout=0.2))(layers.Reshape((1, word_attention_output.shape[-1]))(word_attention_output))\n",
    "    document_lstm = BatchNormalization()(document_lstm)\n",
    "\n",
    "    # Document-Level Attention Layer\n",
    "    document_attention = layers.Attention(use_scale=True)([document_lstm, document_lstm])\n",
    "    document_attention_output = layers.GlobalAveragePooling1D()(document_attention)\n",
    "\n",
    "    # Structured Data Input\n",
    "    structured_input = layers.Input(shape=(X_pad.shape[-1],))\n",
    "\n",
    "    # Combine HAN and Structured Data\n",
    "    combined = layers.concatenate([document_attention_output, structured_input])\n",
    "    combined_output = layers.Dense(64, activation='relu')(combined)\n",
    "    combined_output = layers.Dropout(0.3)(combined_output)  # Increased Dropout\n",
    "    \n",
    "    # Output Layer for Binary Classification\n",
    "    output = layers.Dense(1, activation='sigmoid')(combined_output)\n",
    "    \n",
    "    model = models.Model(inputs=[input_layer, structured_input], outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "input_shape = (1, 3)  # Adjust input shape based on your embeddings\n",
    "model = create_han_model(input_shape)\n",
    "model.summary()\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_pad, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# The structured input should be reshaped to match the model's expectations\n",
    "structured_input_train = X_train[:, 0, :]  # Extracting the structured data component\n",
    "structured_input_val = X_val[:, 0, :]  # Extracting the structured data component\n",
    "\n",
    "# Train the model with callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001)\n",
    "checkpoint = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "history = model.fit(\n",
    "    [X_train, structured_input_train], \n",
    "    y_train, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_data=([X_val, structured_input_val], y_val), \n",
    "    callbacks=[early_stopping, reduce_lr, checkpoint]\n",
    ")\n",
    "\n",
    "# Evaluate the best model\n",
    "model.load_weights('best_model.keras')\n",
    "loss, accuracy = model.evaluate([X_val, structured_input_val], y_val)\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "dda34574-20c4-4440-ae1e-a0f55e1df0cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training and validation loss and accuracy\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "8982864b-28d2-4ce5-b430-0edc791b0fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nidhi\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 86 variables whereas the saved optimizer has 46 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "A total of 19 objects could not be loaded. Example error message for object <LSTMCell name=lstm_cell, built=True>:\n\nThe shape of the target variable and the shape of the target value in `variable.assign(value)` must match. variable.shape=(3, 1024), Received: value.shape=(3, 512). Target variable: <Variable path=bidirectional_59/backward_lstm_71/lstm_cell/kernel, shape=(3, 1024), dtype=float32, value=[[-0.03750969 -0.04184153  0.04430444 ... -0.05281341 -0.04929484\n   0.02571201]\n [-0.00703632 -0.07282057 -0.05664901 ... -0.02233257 -0.01240586\n   0.04326233]\n [ 0.06653496 -0.03620837  0.01984059 ...  0.00345645  0.04699118\n  -0.02978189]]>\n\nList of objects that could not be loaded:\n[<LSTMCell name=lstm_cell, built=True>, <LSTMCell name=lstm_cell, built=True>, <LayerNormalization name=layer_normalization_2, built=True>, <EinsumDense name=key, built=True>, <EinsumDense name=attention_output, built=True>, <EinsumDense name=query, built=True>, <EinsumDense name=value, built=True>, <LSTMCell name=lstm_cell, built=True>, <LSTMCell name=lstm_cell, built=True>, <LayerNormalization name=layer_normalization_3, built=True>, <EinsumDense name=key, built=True>, <EinsumDense name=attention_output, built=True>, <EinsumDense name=query, built=True>, <EinsumDense name=value, built=True>, <Dense name=dense_44, built=True>, <BatchNormalization name=batch_normalization_18, built=True>, <Dense name=dense_45, built=True>, <BatchNormalization name=batch_normalization_19, built=True>, <Dense name=dense_46, built=True>]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[337], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load the best model weights\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model\u001b[38;5;241m.\u001b[39mload_weights(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_model.keras\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Make predictions on the validation set\u001b[39;00m\n\u001b[0;32m      5\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict([X_val, structured_input_val])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:631\u001b[0m, in \u001b[0;36m_raise_loading_failure\u001b[1;34m(error_msgs, warn_only)\u001b[0m\n\u001b[0;32m    629\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(msg)\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 631\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: A total of 19 objects could not be loaded. Example error message for object <LSTMCell name=lstm_cell, built=True>:\n\nThe shape of the target variable and the shape of the target value in `variable.assign(value)` must match. variable.shape=(3, 1024), Received: value.shape=(3, 512). Target variable: <Variable path=bidirectional_59/backward_lstm_71/lstm_cell/kernel, shape=(3, 1024), dtype=float32, value=[[-0.03750969 -0.04184153  0.04430444 ... -0.05281341 -0.04929484\n   0.02571201]\n [-0.00703632 -0.07282057 -0.05664901 ... -0.02233257 -0.01240586\n   0.04326233]\n [ 0.06653496 -0.03620837  0.01984059 ...  0.00345645  0.04699118\n  -0.02978189]]>\n\nList of objects that could not be loaded:\n[<LSTMCell name=lstm_cell, built=True>, <LSTMCell name=lstm_cell, built=True>, <LayerNormalization name=layer_normalization_2, built=True>, <EinsumDense name=key, built=True>, <EinsumDense name=attention_output, built=True>, <EinsumDense name=query, built=True>, <EinsumDense name=value, built=True>, <LSTMCell name=lstm_cell, built=True>, <LSTMCell name=lstm_cell, built=True>, <LayerNormalization name=layer_normalization_3, built=True>, <EinsumDense name=key, built=True>, <EinsumDense name=attention_output, built=True>, <EinsumDense name=query, built=True>, <EinsumDense name=value, built=True>, <Dense name=dense_44, built=True>, <BatchNormalization name=batch_normalization_18, built=True>, <Dense name=dense_45, built=True>, <BatchNormalization name=batch_normalization_19, built=True>, <Dense name=dense_46, built=True>]"
     ]
    }
   ],
   "source": [
    "# Load the best model weights\n",
    "model.load_weights('best_model.keras')\n",
    "\n",
    "# Make predictions on the validation set\n",
    "predictions = model.predict([X_val, structured_input_val])\n",
    "\n",
    "# Threshold for binary classification\n",
    "threshold = 0.5\n",
    "murmur_present_predictions = (predictions > threshold).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "defef694-71d9-4e3f-9f02-ab49a0fa82d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_patient_report(patient_id, murmur_present, severity, murmur_type, location, condition):\n",
    "    return {\n",
    "        \"Patient ID\": patient_id,\n",
    "        \"Murmur Present\": murmur_present,\n",
    "        \"Severity\": severity,\n",
    "        \"Type\": murmur_type,\n",
    "        \"Most Audible Location\": location,\n",
    "        \"Associated Conditions\": condition\n",
    "    }\n",
    "\n",
    "# Map predictions to associated conditions (example function, you might need actual logic here)\n",
    "def map_to_condition(location, severity, murmur_type):\n",
    "    # Example logic, replace with actual mapping\n",
    "    if location == \"Mitral Valve\" and severity == \"Grade III\" and murmur_type == \"Systolic\":\n",
    "        return \"Mitral Regurgitation\"\n",
    "    return \"Unknown Condition\"\n",
    "\n",
    "# Placeholder predictions for severity, type, and location\n",
    "severity_predictions = [\"Grade III\" for _ in range(len(predictions))]  # Replace with actual prediction logic\n",
    "type_predictions = [\"Systolic\" for _ in range(len(predictions))]  # Replace with actual prediction logic\n",
    "location_predictions = [\"Mitral Valve\" for _ in range(len(predictions))]  # Replace with actual prediction logic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "4df9abec-cbf0-4310-ba9c-1b2b7b8cfc9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Patient ID': 13918, 'Murmur Present': False, 'Severity': 'N/A', 'Type': 'N/A', 'Most Audible Location': 'N/A', 'Associated Conditions': 'None'}\n"
     ]
    }
   ],
   "source": [
    "# Generate reports based on model predictions\n",
    "reports = []\n",
    "for i in range(len(predictions)):\n",
    "    patient_id = df.iloc[i]['Patient ID']  # Assuming 'Patient ID' column exists in your dataframe\n",
    "    murmur_present = bool(murmur_present_predictions[i][0])\n",
    "    \n",
    "    if murmur_present:\n",
    "        severity = severity_predictions[i]\n",
    "        murmur_type = type_predictions[i]\n",
    "        location = location_predictions[i]\n",
    "        condition = map_to_condition(location, severity, murmur_type)\n",
    "    else:\n",
    "        severity = \"N/A\"\n",
    "        murmur_type = \"N/A\"\n",
    "        location = \"N/A\"\n",
    "        condition = \"None\"\n",
    "    \n",
    "    report = generate_patient_report(\n",
    "        patient_id=patient_id,\n",
    "        murmur_present=murmur_present,\n",
    "        severity=severity,\n",
    "        murmur_type=murmur_type,\n",
    "        location=location,\n",
    "        condition=condition\n",
    "    )\n",
    "    reports.append(report)\n",
    "\n",
    "# Print a sample report for the first patient\n",
    "print(reports[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "f33990b4-bd2b-45ea-9283-c86736265ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Patient ID', 'Age', 'Sex', 'Height', 'Weight', 'Pregnancy status',\n",
      "       'Murmur', 'Murmur locations', 'Most audible location',\n",
      "       'Systolic murmur timing', 'Systolic murmur shape',\n",
      "       'Systolic murmur grading', 'Systolic murmur pitch',\n",
      "       'Systolic murmur quality', 'Diastolic murmur timing',\n",
      "       'Diastolic murmur shape', 'Diastolic murmur grading',\n",
      "       'Diastolic murmur pitch', 'Diastolic murmur quality', 'Outcome',\n",
      "       'Campaign', 'Additional ID', 'AV Sound Type', 'AV Murmur Timings',\n",
      "       'PV Sound Type', 'PV Murmur Timings', 'TV Sound Type',\n",
      "       'TV Murmur Timings', 'MV Sound Type', 'MV Murmur Timings'],\n",
      "      dtype='object')\n",
      "Empty DataFrame\n",
      "Columns: [Patient ID, Age, Sex, Height, Weight, Pregnancy status, Murmur, Murmur locations, Most audible location, Systolic murmur timing, Systolic murmur shape, Systolic murmur grading, Systolic murmur pitch, Systolic murmur quality, Diastolic murmur timing, Diastolic murmur shape, Diastolic murmur grading, Diastolic murmur pitch, Diastolic murmur quality, Outcome, Campaign, Additional ID, AV Sound Type, AV Murmur Timings, PV Sound Type, PV Murmur Timings, TV Sound Type, TV Murmur Timings, MV Sound Type, MV Murmur Timings]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# Check if these columns exist in the DataFrame\n",
    "print(df.columns)\n",
    "\n",
    "# Check the first few rows of the DataFrame to ensure data is present\n",
    "print(df.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
